#!/usr/bin/env python3
"""
æœ¬åœ°å¤§æ¨¡å‹é‡‡æ · -> æœ¬åœ°å°æ¨¡å‹å¾®è°ƒçš„BTPå®éªŒ
ä¸“é—¨è®¾è®¡ç”¨äºæœ¬åœ°æ¨¡å‹çš„å¾®è°ƒå®éªŒï¼Œæ— éœ€APIè°ƒç”¨
"""

import os
import sys
import json
import argparse
import torch
import numpy as np
import random
from datetime import datetime
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict, deque
from typing import List, Dict, Any, Optional
import logging
import gc

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

try:
    # Transformersç›¸å…³å¯¼å…¥
    from transformers import (
        AutoModelForCausalLM, 
        AutoTokenizer, 
        Trainer, 
        TrainingArguments,
        DataCollatorForLanguageModeling,
        GenerationConfig
    )
    from peft import LoraConfig, get_peft_model, TaskType
    from datasets import Dataset
except ImportError as e:
    print(f"Missing dependencies: {e}")
    print("Please install: pip install transformers peft datasets")
    sys.exit(1)

# é¡¹ç›®ç›¸å…³å¯¼å…¥
from eg_cfg.mbpp_utils import load_mbpp_problems, run_tests


class P2ValueCalculator:
    """P2Valueè®¡ç®—å™¨ï¼šå¹³è¡¡å¯èƒ½æ€§å’Œé€šè¿‡ç‡"""
    
    def __init__(self, alpha: float = 0.7):
        self.alpha = alpha
    
    def calculate_p2value(self, possibility: float, pass_rate: float) -> float:
        """è®¡ç®—P2Value = Î± Ã— pass_rate + (1-Î±) Ã— possibility"""
        return self.alpha * pass_rate + (1 - self.alpha) * possibility


class PrioritizedSampler:
    """ä¼˜å…ˆç»éªŒé‡‡æ ·å™¨"""
    
    def __init__(self, sampling_method: str = "power", alpha: float = 1.5):
        self.sampling_method = sampling_method
        self.alpha = alpha
    
    def sample(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """æ ¹æ®P2Valueè¿›è¡Œä¼˜å…ˆé‡‡æ ·"""
        if not experiences:
            return []
        
        if self.sampling_method == "power":
            return self._power_sampling(experiences, batch_size)
        elif self.sampling_method == "rank":
            return self._rank_sampling(experiences, batch_size)
        else:
            raise ValueError(f"Unknown sampling method: {self.sampling_method}")
    
    def _power_sampling(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """å¹‚æ¬¡é‡‡æ ·: P(i) = pi^Î± / Î£ pk^Î±"""
        p2values = np.array([exp['p2value'] for exp in experiences])
        p2values = np.maximum(p2values, 1e-8)  # é¿å…é™¤é›¶
        
        # è®¡ç®—é‡‡æ ·æ¦‚ç‡
        powered_values = np.power(p2values, self.alpha)
        probabilities = powered_values / np.sum(powered_values)
        
        # é‡‡æ ·
        indices = np.random.choice(
            len(experiences), 
            size=min(batch_size, len(experiences)), 
            p=probabilities, 
            replace=False
        )
        
        return [experiences[i] for i in indices]
    
    def _rank_sampling(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """æ’åé‡‡æ ·: pi = 1/rank(i)"""
        sorted_experiences = sorted(experiences, key=lambda x: x['p2value'], reverse=True)
        
        ranks = np.arange(1, len(sorted_experiences) + 1)
        probabilities = 1.0 / ranks
        probabilities = probabilities / np.sum(probabilities)
        
        indices = np.random.choice(
            len(sorted_experiences), 
            size=min(batch_size, len(sorted_experiences)), 
            p=probabilities, 
            replace=False
        )
        
        return [sorted_experiences[i] for i in indices]


class ExperienceReplayBuffer:
    """ç»éªŒå›æ”¾ç¼“å†²åŒº"""
    
    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self.buffer = deque(maxlen=max_size)
        self.p2calculator = P2ValueCalculator()
    
    def add_experience(self, experience: Dict):
        """æ·»åŠ ç»éªŒåˆ°ç¼“å†²åŒº"""
        if 'p2value' not in experience:
            experience['p2value'] = self.p2calculator.calculate_p2value(
                experience['possibility'], 
                experience['pass_rate']
            )
        self.buffer.append(experience)
    
    def get_all_experiences(self) -> List[Dict]:
        return list(self.buffer)
    
    def get_stats(self) -> Dict:
        """è·å–ç¼“å†²åŒºç»Ÿè®¡ä¿¡æ¯"""
        if not self.buffer:
            return {'total_experiences': 0}
        
        experiences = list(self.buffer)
        p2values = [exp['p2value'] for exp in experiences]
        pass_rates = [exp['pass_rate'] for exp in experiences]
        
        return {
            'total_experiences': len(experiences),
            'avg_p2value': np.mean(p2values),
            'std_p2value': np.std(p2values),
            'avg_pass_rate': np.mean(pass_rates),
            'perfect_solutions': sum(1 for exp in experiences if exp['pass_rate'] >= 1.0),
            'zero_pass_solutions': sum(1 for exp in experiences if exp['pass_rate'] == 0.0)
        }


class LocalModelManager:
    """æœ¬åœ°æ¨¡å‹ç®¡ç†å™¨ - ä¸“é—¨å¤„ç†æœ¬åœ°å¤§å°æ¨¡å‹"""
    
    def __init__(self, 
                 source_model_path: str,
                 target_model_path: str,
                 use_lora: bool = True,
                 lora_config: Optional[Dict] = None):
        
        self.source_model_path = source_model_path
        self.target_model_path = target_model_path
        self.use_lora = use_lora
        
        print("ğŸš€ åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹ç®¡ç†å™¨")
        print(f"ğŸ“Š æºæ¨¡å‹ï¼ˆé‡‡æ ·ï¼‰: {source_model_path}")
        print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹ï¼ˆå¾®è°ƒï¼‰: {target_model_path}")
        
        # åŠ è½½tokenizerï¼ˆå…±äº«ï¼‰
        self.tokenizer = AutoTokenizer.from_pretrained(
            source_model_path, 
            trust_remote_code=True,
            padding_side='left'
        )
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # åŠ è½½æºæ¨¡å‹ï¼ˆç”¨äºé‡‡æ ·ï¼‰
        self._load_source_model()
        
        # åŠ è½½ç›®æ ‡æ¨¡å‹ï¼ˆç”¨äºå¾®è°ƒï¼‰
        self._load_target_model(lora_config)
    
    def _load_source_model(self):
        """åŠ è½½æºæ¨¡å‹ç”¨äºé‡‡æ ·"""
        print(f"ğŸ”„ åŠ è½½æºæ¨¡å‹: {self.source_model_path}")
        
        self.source_model = AutoModelForCausalLM.from_pretrained(
            self.source_model_path,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True,
            low_cpu_mem_usage=True
        )
        
        # è®¾ç½®ç”Ÿæˆé…ç½®
        self.generation_config = GenerationConfig(
            do_sample=True,
            temperature=0.8,
            top_p=0.95,
            max_new_tokens=512,
            num_return_sequences=1,
            pad_token_id=self.tokenizer.pad_token_id,
            eos_token_id=self.tokenizer.eos_token_id,
        )
        
        print(f"âœ… æºæ¨¡å‹åŠ è½½å®Œæˆï¼Œæ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated() / 1024**3:.2f}GB")
    
    def _load_target_model(self, lora_config: Optional[Dict]):
        """åŠ è½½ç›®æ ‡æ¨¡å‹ç”¨äºå¾®è°ƒ"""
        print(f"ğŸ”„ åŠ è½½ç›®æ ‡æ¨¡å‹: {self.target_model_path}")
        
        self.target_model = AutoModelForCausalLM.from_pretrained(
            self.target_model_path,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True,
            low_cpu_mem_usage=True
        )
        
        # é…ç½®LoRA
        if self.use_lora:
            lora_config = lora_config or {
                'r': 32,
                'lora_alpha': 64,
                'target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],
                'lora_dropout': 0.05,
                'bias': 'none',
                'task_type': TaskType.CAUSAL_LM
            }
            
            peft_config = LoraConfig(**lora_config)
            self.target_model = get_peft_model(self.target_model, peft_config)
            self.target_model.print_trainable_parameters()
        
        print(f"âœ… ç›®æ ‡æ¨¡å‹åŠ è½½å®Œæˆï¼Œæ€»æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated() / 1024**3:.2f}GB")
    
    def generate_beam_candidates(self, 
                               prompt: str, 
                               num_beams: int = 8, 
                               max_new_tokens: int = 512) -> List[Dict]:
        """ä½¿ç”¨æºæ¨¡å‹ç”Ÿæˆbeam searchå€™é€‰"""
        
        # ç¼–ç è¾“å…¥
        inputs = self.tokenizer(prompt, return_tensors="pt", padding=True)
        inputs = {k: v.to(self.source_model.device) for k, v in inputs.items()}
        
        # ç”Ÿæˆé…ç½®
        generation_config = GenerationConfig(
            do_sample=True,
            num_beams=num_beams,
            num_return_sequences=num_beams,
            temperature=0.8,
            top_p=0.95,
            max_new_tokens=max_new_tokens,
            pad_token_id=self.tokenizer.pad_token_id,
            eos_token_id=self.tokenizer.eos_token_id,
            output_scores=True,
            return_dict_in_generate=True,
        )
        
        # ç”Ÿæˆ
        with torch.no_grad():
            outputs = self.source_model.generate(
                **inputs,
                generation_config=generation_config
            )
        
        # è§£æç»“æœ
        candidates = []
        sequences = outputs.sequences
        scores = outputs.sequences_scores if hasattr(outputs, 'sequences_scores') else None
        
        for i in range(num_beams):
            # è§£ç ç”Ÿæˆçš„åºåˆ—
            generated_sequence = sequences[i]
            generated_text = self.tokenizer.decode(
                generated_sequence[inputs['input_ids'].shape[1]:], 
                skip_special_tokens=True
            )
            
            # æå–ä»£ç 
            code = self._extract_code_from_text(generated_text)
            
            # è®¡ç®—å¯èƒ½æ€§ï¼ˆä½¿ç”¨åˆ†æ•°æˆ–é»˜è®¤å€¼ï¼‰
            possibility = float(scores[i]) if scores is not None else 1.0 / (i + 1)
            
            candidates.append({
                'code': code,
                'raw_text': generated_text,
                'possibility': possibility,
                'beam_rank': i
            })
        
        return candidates
    
    def _extract_code_from_text(self, text: str) -> str:
        """ä»ç”Ÿæˆçš„æ–‡æœ¬ä¸­æå–Pythonä»£ç """
        import re
        
        # å°è¯•æå–```pythonä»£ç å—
        python_pattern = r'```python\n(.*?)```'
        match = re.search(python_pattern, text, re.DOTALL)
        if match:
            return match.group(1).strip()
        
        # å°è¯•æå–```ä»£ç å—  
        code_pattern = r'```\n(.*?)```'
        match = re.search(code_pattern, text, re.DOTALL)
        if match:
            return match.group(1).strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œè¿”å›æ•´ä¸ªæ–‡æœ¬
        return text.strip()
    
    def clear_source_model_cache(self):
        """æ¸…ç†æºæ¨¡å‹ç¼“å­˜ä»¥èŠ‚çœæ˜¾å­˜"""
        if hasattr(self, 'source_model'):
            del self.source_model
            torch.cuda.empty_cache()
            gc.collect()
            print("ğŸ§¹ æºæ¨¡å‹ç¼“å­˜å·²æ¸…ç†")


class LocalBTPFineTuneExperiment:
    """æœ¬åœ°BTPå¾®è°ƒå®éªŒä¸»ç±»"""
    
    def __init__(self, 
                 source_model_path: str,
                 target_model_path: str,
                 dataset: str = "mbpp",
                 sampling_method: str = "power",
                 sampling_alpha: float = 1.5,
                 p2value_alpha: float = 0.7,
                 use_lora: bool = True,
                 lora_config: Optional[Dict] = None):
        
        self.dataset = dataset
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.p2calculator = P2ValueCalculator(p2value_alpha)
        self.sampler = PrioritizedSampler(sampling_method, sampling_alpha)
        self.experience_buffer = ExperienceReplayBuffer()
        
        # åŠ è½½æ•°æ®é›†
        if dataset == "mbpp":
            self.problems = load_mbpp_problems()
        else:
            raise ValueError(f"Unsupported dataset: {dataset}")
        
        # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        self.model_manager = LocalModelManager(
            source_model_path, 
            target_model_path,
            use_lora,
            lora_config
        )
        
        print("=" * 60)
        print("ğŸš€ æœ¬åœ°BTPå¾®è°ƒå®éªŒåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š é‡‡æ ·æ–¹æ³•: {sampling_method} (Î±={sampling_alpha})")
        print(f"ğŸ¯ P2Valueæƒé‡: pass_rate={p2value_alpha}, possibility={1-p2value_alpha}")
        print(f"ğŸ”§ ä½¿ç”¨LoRA: {use_lora}")
        print("=" * 60)
    
    def format_problem_prompt(self, problem: Dict) -> str:
        """æ ¼å¼åŒ–é—®é¢˜ä¸ºæ¨¡å‹è¾“å…¥"""
        prompt = f"""Solve the following programming problem:

{problem['text']}

Please provide a complete Python function that solves this problem.

```python
"""
        return prompt
    
    def phase1_beam_search_sampling(self, problems: List[Dict], num_beams: int = 8) -> None:
        """é˜¶æ®µ1: ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡ŒBeam Searché‡‡æ ·"""
        print("=" * 40)
        print("ğŸ“Š é˜¶æ®µ1: Beam Searché‡‡æ ·")
        print("=" * 40)
        
        for problem_id, problem in tqdm(problems, desc="ğŸ” é‡‡æ ·ä»£ç å€™é€‰"):
            prompt = self.format_problem_prompt(problem)
            
            try:
                # ç”Ÿæˆå€™é€‰
                candidates = self.model_manager.generate_beam_candidates(
                    prompt, num_beams=num_beams
                )
                
                # æµ‹è¯•æ¯ä¸ªå€™é€‰
                for candidate in candidates:
                    try:
                        # è¿è¡Œæµ‹è¯•
                        test_results = run_tests(candidate['code'], problem['test_list'])
                        passed_tests = sum(1 for r in test_results.values() if r.get('result', False))
                        total_tests = len(test_results)
                        pass_rate = passed_tests / total_tests if total_tests > 0 else 0.0
                        
                        # åˆ›å»ºç»éªŒ
                        experience = {
                            'problem_id': problem_id,
                            'problem_text': problem['text'],
                            'code': candidate['code'],
                            'possibility': candidate['possibility'],
                            'pass_rate': pass_rate,
                            'test_results': test_results,
                            'beam_rank': candidate['beam_rank'],
                            'passed_tests': passed_tests,
                            'total_tests': total_tests
                        }
                        
                        self.experience_buffer.add_experience(experience)
                        
                    except Exception as e:
                        # æµ‹è¯•å¤±è´¥ï¼Œè®°å½•ä¸º0é€šè¿‡ç‡
                        experience = {
                            'problem_id': problem_id,
                            'problem_text': problem['text'],
                            'code': candidate['code'],
                            'possibility': candidate['possibility'],
                            'pass_rate': 0.0,
                            'error': str(e),
                            'beam_rank': candidate['beam_rank'],
                            'passed_tests': 0,
                            'total_tests': len(problem['test_list'])
                        }
                        self.experience_buffer.add_experience(experience)
                        
            except Exception as e:
                print(f"âŒ é—®é¢˜ {problem_id} ç”Ÿæˆå¤±è´¥: {e}")
                continue
        
        # æ˜¾ç¤ºé‡‡æ ·ç»Ÿè®¡
        stats = self.experience_buffer.get_stats()
        print("\nğŸ“ˆ é‡‡æ ·ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
    
    def phase2_pper_training(self, 
                           n_iterations: int = 3,
                           batch_size: int = 32,
                           training_args: Optional[TrainingArguments] = None) -> None:
        """é˜¶æ®µ2: ä¼˜å…ˆç»éªŒå›æ”¾è®­ç»ƒ"""
        print("\n" + "=" * 40)
        print("ğŸ¯ é˜¶æ®µ2: PPERå¾®è°ƒè®­ç»ƒ")
        print("=" * 40)
        
        # æ¸…ç†æºæ¨¡å‹ä»¥èŠ‚çœæ˜¾å­˜
        self.model_manager.clear_source_model_cache()
        
        for iteration in range(n_iterations):
            print(f"\nğŸ”„ è¿­ä»£ {iteration + 1}/{n_iterations}")
            
            # ä¼˜å…ˆé‡‡æ ·
            all_experiences = self.experience_buffer.get_all_experiences()
            sampled_experiences = self.sampler.sample(all_experiences, batch_size)
            
            print(f"ğŸ“¦ é‡‡æ ·äº† {len(sampled_experiences)} ä¸ªé«˜è´¨é‡ç»éªŒ")
            
            # æ˜¾ç¤ºé‡‡æ ·è´¨é‡
            avg_pass_rate = np.mean([exp['pass_rate'] for exp in sampled_experiences])
            avg_p2value = np.mean([exp['p2value'] for exp in sampled_experiences])
            print(f"ğŸ“Š å¹³å‡é€šè¿‡ç‡: {avg_pass_rate:.3f}, å¹³å‡P2Value: {avg_p2value:.3f}")
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            train_dataset = self._prepare_training_dataset(sampled_experiences)
            
            # æ‰§è¡Œå¾®è°ƒ
            self._finetune_model(train_dataset, training_args, iteration)
    
    def _prepare_training_dataset(self, experiences: List[Dict]) -> Dataset:
        """å‡†å¤‡å¾®è°ƒè®­ç»ƒæ•°æ®é›†"""
        texts = []
        
        for exp in experiences:
            # æŒ‡ä»¤å¾®è°ƒæ ¼å¼
            instruction = f"Solve this programming problem:\n{exp['problem_text']}"
            response = exp['code']
            
            # æ ¼å¼åŒ–è®­ç»ƒæ–‡æœ¬
            text = f"### Instruction:\n{instruction}\n\n### Response:\n{response}{self.model_manager.tokenizer.eos_token}"
            texts.append(text)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = Dataset.from_dict({'text': texts})
        
        # åˆ†è¯
        def tokenize_function(examples):
            tokenized = self.model_manager.tokenizer(
                examples['text'],
                truncation=True,
                padding=True,
                max_length=1024,
                return_tensors="pt"
            )
            tokenized["labels"] = tokenized["input_ids"].clone()
            return tokenized
        
        tokenized_dataset = dataset.map(
            tokenize_function, 
            batched=True, 
            remove_columns=['text']
        )
        
        return tokenized_dataset
    
    def _finetune_model(self, 
                       train_dataset: Dataset, 
                       training_args: Optional[TrainingArguments],
                       iteration: int) -> None:
        """æ‰§è¡Œæ¨¡å‹å¾®è°ƒ"""
        
        if training_args is None:
            training_args = TrainingArguments(
                output_dir=f"./local_btp_checkpoints/iteration_{iteration}",
                num_train_epochs=2,
                per_device_train_batch_size=2,
                gradient_accumulation_steps=8,
                warmup_steps=50,
                learning_rate=1e-4,
                fp16=True,
                logging_steps=10,
                save_steps=100,
                save_total_limit=2,
                remove_unused_columns=False,
                dataloader_num_workers=0,
                report_to=None
            )
        
        # æ•°æ®æ•´ç†å™¨
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.model_manager.tokenizer,
            mlm=False,
        )
        
        # è®­ç»ƒå™¨
        trainer = Trainer(
            model=self.model_manager.target_model,
            args=training_args,
            train_dataset=train_dataset,
            data_collator=data_collator,
        )
        
        # å¼€å§‹è®­ç»ƒ
        print(f"ğŸš€ å¼€å§‹å¾®è°ƒè¿­ä»£ {iteration}...")
        trainer.train()
        
        # ä¿å­˜æ¨¡å‹
        trainer.save_model()
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ° {training_args.output_dir}")
    
    def run_experiment(self, 
                      max_problems: int = 50,
                      num_beams: int = 8,
                      n_iterations: int = 3,
                      batch_size: int = 32,
                      output_dir: str = "./local_btp_results") -> Dict:
        """è¿è¡Œå®Œæ•´çš„BTPå®éªŒ"""
        
        print("=" * 80)
        print("ğŸš€ æœ¬åœ°BTPå¾®è°ƒå®éªŒå¼€å§‹")
        print("=" * 80)
        
        # é€‰æ‹©é—®é¢˜å­é›†
        problems_list = list(self.problems.items())[:max_problems]
        print(f"ğŸ“‹ å¤„ç† {len(problems_list)} ä¸ªç¼–ç¨‹é—®é¢˜")
        
        # é˜¶æ®µ1: Beam Searché‡‡æ ·
        self.phase1_beam_search_sampling(problems_list, num_beams)
        
        # æ˜¾ç¤ºåˆå§‹ç»Ÿè®¡
        initial_stats = self.experience_buffer.get_stats()
        print(f"\nğŸ“Š åˆå§‹ç»éªŒç»Ÿè®¡:")
        for key, value in initial_stats.items():
            print(f"  {key}: {value}")
        
        # é˜¶æ®µ2: PPERå¾®è°ƒ
        self.phase2_pper_training(n_iterations, batch_size)
        
        # ä¿å­˜å®éªŒç»“æœ
        results = {
            'experiment_type': 'Local_BTP_FineTune',
            'source_model': self.model_manager.source_model_path,
            'target_model': self.model_manager.target_model_path,
            'dataset': self.dataset,
            'sampling_method': self.sampler.sampling_method,
            'sampling_alpha': self.sampler.alpha,
            'p2value_alpha': self.p2calculator.alpha,
            'max_problems': max_problems,
            'num_beams': num_beams,
            'n_iterations': n_iterations,
            'batch_size': batch_size,
            'initial_stats': initial_stats,
            'final_stats': self.experience_buffer.get_stats(),
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜ç»“æœ
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_file = os.path.join(output_dir, f"local_btp_results_{timestamp}.json")
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“Š å®éªŒç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        print("=" * 80)
        print("âœ… æœ¬åœ°BTPå¾®è°ƒå®éªŒå®Œæˆ!")
        print("=" * 80)
        
        return results


def main():
    parser = argparse.ArgumentParser(description='æœ¬åœ°å¤§æ¨¡å‹->å°æ¨¡å‹BTPå¾®è°ƒå®éªŒ')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--source-model', type=str, 
                       default='deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct',
                       help='æºæ¨¡å‹è·¯å¾„ï¼ˆç”¨äºé‡‡æ ·ï¼‰')
    parser.add_argument('--target-model', type=str, 
                       default='deepseek-ai/deepseek-coder-1.3b-instruct',
                       help='ç›®æ ‡æ¨¡å‹è·¯å¾„ï¼ˆç”¨äºå¾®è°ƒï¼‰')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--max-problems', type=int, default=50,
                       help='æœ€å¤§é—®é¢˜æ•°é‡')
    parser.add_argument('--num-beams', type=int, default=8,
                       help='Beam Searchå€™é€‰æ•°é‡')
    parser.add_argument('--n-iterations', type=int, default=3,
                       help='å¾®è°ƒè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='æ¯æ¬¡å¾®è°ƒçš„æ‰¹æ¬¡å¤§å°')
    
    # é‡‡æ ·å‚æ•°
    parser.add_argument('--sampling-method', type=str, default='power', 
                       choices=['power', 'rank'],
                       help='é‡‡æ ·æ–¹æ³•')
    parser.add_argument('--sampling-alpha', type=float, default=1.5,
                       help='é‡‡æ ·Î±å‚æ•°')
    parser.add_argument('--p2value-alpha', type=float, default=0.7,
                       help='P2Value Î±å‚æ•°')
    
    # LoRAå‚æ•°
    parser.add_argument('--lora-r', type=int, default=32,
                       help='LoRA rank')
    parser.add_argument('--lora-alpha', type=int, default=64,
                       help='LoRA alpha')
    parser.add_argument('--lora-dropout', type=float, default=0.05,
                       help='LoRA dropout')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--learning-rate', type=float, default=1e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--num-epochs', type=int, default=2,
                       help='æ¯æ¬¡è¿­ä»£çš„è®­ç»ƒè½®æ•°')
    parser.add_argument('--per-device-batch-size', type=int, default=2,
                       help='æ¯è®¾å¤‡æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--gradient-accumulation-steps', type=int, default=8,
                       help='æ¢¯åº¦ç´¯ç§¯æ­¥æ•°')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-dir', type=str, default='./local_btp_results',
                       help='ç»“æœè¾“å‡ºç›®å½•')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)
    
    # LoRAé…ç½®
    lora_config = {
        'r': args.lora_r,
        'lora_alpha': args.lora_alpha,
        'lora_dropout': args.lora_dropout,
        'target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],
        'bias': 'none',
        'task_type': 'CAUSAL_LM'
    }
    
    # æ‰“å°é…ç½®
    print("ğŸ”§ æœ¬åœ°BTPå¾®è°ƒå®éªŒé…ç½®:")
    print(f"  ğŸ“Š æºæ¨¡å‹: {args.source_model}")
    print(f"  ğŸ¯ ç›®æ ‡æ¨¡å‹: {args.target_model}")
    print(f"  ğŸ“‹ é—®é¢˜æ•°é‡: {args.max_problems}")
    print(f"  ğŸ” Beamæ•°é‡: {args.num_beams}")
    print(f"  ğŸ”„ è¿­ä»£æ¬¡æ•°: {args.n_iterations}")
    print(f"  ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"  ğŸ² é‡‡æ ·æ–¹æ³•: {args.sampling_method} (Î±={args.sampling_alpha})")
    print(f"  âš–ï¸ P2Valueæƒé‡: {args.p2value_alpha}")
    print(f"  ğŸ”§ LoRA: r={args.lora_r}, Î±={args.lora_alpha}, dropout={args.lora_dropout}")
    print()
    
    # åˆ›å»ºè®­ç»ƒå‚æ•°
    training_args = TrainingArguments(
        output_dir=f"{args.output_dir}/checkpoints",
        num_train_epochs=args.num_epochs,
        per_device_train_batch_size=args.per_device_batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        learning_rate=args.learning_rate,
        warmup_steps=50,
        logging_steps=10,
        save_steps=100,
        save_total_limit=2,
        fp16=True,
        remove_unused_columns=False,
        dataloader_num_workers=0,
        report_to=None
    )
    
    # åˆ›å»ºå®éªŒ
    experiment = LocalBTPFineTuneExperiment(
        source_model_path=args.source_model,
        target_model_path=args.target_model,
        dataset="mbpp",
        sampling_method=args.sampling_method,
        sampling_alpha=args.sampling_alpha,
        p2value_alpha=args.p2value_alpha,
        use_lora=True,
        lora_config=lora_config
    )
    
    # è¿è¡Œå®éªŒ
    results = experiment.run_experiment(
        max_problems=args.max_problems,
        num_beams=args.num_beams,
        n_iterations=args.n_iterations,
        batch_size=args.batch_size,
        output_dir=args.output_dir
    )
    
    print("ğŸ‰ å®éªŒå®Œæˆ!")
    final_stats = results['final_stats']
    print(f"ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
    for key, value in final_stats.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    main() 