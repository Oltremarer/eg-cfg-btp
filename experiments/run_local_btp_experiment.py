#!/usr/bin/env python3
"""
æœ¬åœ°BTPå®éªŒå¿«é€Ÿå¯åŠ¨è„šæœ¬
å°è£…å¸¸ç”¨é…ç½®ï¼Œæ–¹ä¾¿å¿«é€Ÿå¯åŠ¨å®éªŒ
"""

import os
import sys
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from big_to_small_finetune_experiment import LocalBTPFineTuneExperiment
from transformers import TrainingArguments


def get_model_configs():
    """é¢„å®šä¹‰çš„æ¨¡å‹é…ç½®"""
    return {
        "small_to_small": {
            "source_model": "deepseek-ai/deepseek-coder-1.3b-instruct",
            "target_model": "deepseek-ai/deepseek-coder-1.3b-instruct",
            "description": "1.3Bæ¨¡å‹è‡ªä¸¾å®éªŒ"
        },
        "medium_to_small": {
            "source_model": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
            "target_model": "deepseek-ai/deepseek-coder-1.3b-instruct", 
            "description": "6.7B -> 1.3B æ¨èé…ç½®"
        },
        "medium_to_medium": {
            "source_model": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
            "target_model": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
            "description": "6.7Bæ¨¡å‹è‡ªä¸¾å®éªŒ"
        }
    }


def get_experiment_presets():
    """é¢„å®šä¹‰çš„å®éªŒé…ç½®"""
    return {
        "quick": {
            "max_problems": 20,
            "num_beams": 5,
            "n_iterations": 2,
            "batch_size": 16,
            "description": "å¿«é€ŸéªŒè¯ï¼ˆ20åˆ†é’Ÿï¼‰"
        },
        "small": {
            "max_problems": 30,
            "num_beams": 6,
            "n_iterations": 3,
            "batch_size": 24,
            "description": "å°è§„æ¨¡å®éªŒï¼ˆ40åˆ†é’Ÿï¼‰"
        },
        "medium": {
            "max_problems": 50,
            "num_beams": 8,
            "n_iterations": 3,
            "batch_size": 32,
            "description": "ä¸­ç­‰è§„æ¨¡å®éªŒï¼ˆ70åˆ†é’Ÿï¼‰"
        },
        "large": {
            "max_problems": 100,
            "num_beams": 10,
            "n_iterations": 4,
            "batch_size": 48,
            "description": "å¤§è§„æ¨¡å®éªŒï¼ˆ2-3å°æ—¶ï¼‰"
        }
    }


def create_optimized_training_args(output_dir: str, experiment_size: str):
    """æ ¹æ®å®éªŒè§„æ¨¡åˆ›å»ºä¼˜åŒ–çš„è®­ç»ƒå‚æ•°"""
    
    base_config = {
        "output_dir": output_dir,
        "fp16": True,
        "remove_unused_columns": False,
        "dataloader_num_workers": 0,
        "report_to": None,
        "save_total_limit": 2,
        "logging_steps": 10,
    }
    
    if experiment_size == "quick":
        config = {
            **base_config,
            "num_train_epochs": 1,
            "per_device_train_batch_size": 2,
            "gradient_accumulation_steps": 4,
            "learning_rate": 2e-4,
            "warmup_steps": 20,
            "save_steps": 50,
        }
    elif experiment_size == "small":
        config = {
            **base_config,
            "num_train_epochs": 2,
            "per_device_train_batch_size": 2,
            "gradient_accumulation_steps": 6,
            "learning_rate": 1e-4,
            "warmup_steps": 30,
            "save_steps": 100,
        }
    elif experiment_size == "medium":
        config = {
            **base_config,
            "num_train_epochs": 2,
            "per_device_train_batch_size": 2,
            "gradient_accumulation_steps": 8,
            "learning_rate": 1e-4,
            "warmup_steps": 50,
            "save_steps": 100,
        }
    else:  # large
        config = {
            **base_config,
            "num_train_epochs": 3,
            "per_device_train_batch_size": 1,
            "gradient_accumulation_steps": 16,
            "learning_rate": 5e-5,
            "warmup_steps": 100,
            "save_steps": 200,
        }
    
    return TrainingArguments(**config)


def main():
    parser = argparse.ArgumentParser(description='æœ¬åœ°BTPå®éªŒå¿«é€Ÿå¯åŠ¨')
    
    # é¢„è®¾é…ç½®
    parser.add_argument('--model-config', type=str, 
                       choices=list(get_model_configs().keys()),
                       default='medium_to_small',
                       help='æ¨¡å‹é…ç½®é¢„è®¾')
    
    parser.add_argument('--experiment-size', type=str,
                       choices=list(get_experiment_presets().keys()),
                       default='small',
                       help='å®éªŒè§„æ¨¡é¢„è®¾')
    
    # è‡ªå®šä¹‰å‚æ•°ï¼ˆå¯è¦†ç›–é¢„è®¾ï¼‰
    parser.add_argument('--source-model', type=str, help='æºæ¨¡å‹è·¯å¾„ï¼ˆè¦†ç›–é¢„è®¾ï¼‰')
    parser.add_argument('--target-model', type=str, help='ç›®æ ‡æ¨¡å‹è·¯å¾„ï¼ˆè¦†ç›–é¢„è®¾ï¼‰')
    parser.add_argument('--max-problems', type=int, help='é—®é¢˜æ•°é‡ï¼ˆè¦†ç›–é¢„è®¾ï¼‰')
    parser.add_argument('--num-beams', type=int, help='Beamæ•°é‡ï¼ˆè¦†ç›–é¢„è®¾ï¼‰')
    parser.add_argument('--batch-size', type=int, help='æ‰¹æ¬¡å¤§å°ï¼ˆè¦†ç›–é¢„è®¾ï¼‰')
    
    # é‡‡æ ·å‚æ•°
    parser.add_argument('--sampling-method', type=str, default='power',
                       choices=['power', 'rank'], help='é‡‡æ ·æ–¹æ³•')
    parser.add_argument('--sampling-alpha', type=float, default=1.5,
                       help='é‡‡æ ·Î±å‚æ•°')
    parser.add_argument('--p2value-alpha', type=float, default=0.7,
                       help='P2Value Î±å‚æ•°ï¼ˆé‡è§†é€šè¿‡ç‡ï¼‰')
    
    # è¾“å‡º
    parser.add_argument('--output-dir', type=str, 
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰')
    
    # å…¶ä»–
    parser.add_argument('--dry-run', action='store_true',
                       help='åªæ˜¾ç¤ºé…ç½®ï¼Œä¸è¿è¡Œå®éªŒ')
    
    args = parser.parse_args()
    
    # è·å–é¢„è®¾é…ç½®
    model_configs = get_model_configs()
    experiment_presets = get_experiment_presets()
    
    model_config = model_configs[args.model_config]
    experiment_preset = experiment_presets[args.experiment_size]
    
    # åº”ç”¨è‡ªå®šä¹‰å‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
    source_model = args.source_model or model_config['source_model']
    target_model = args.target_model or model_config['target_model']
    max_problems = args.max_problems or experiment_preset['max_problems']
    num_beams = args.num_beams or experiment_preset['num_beams']
    n_iterations = experiment_preset['n_iterations']
    batch_size = args.batch_size or experiment_preset['batch_size']
    
    # ç”Ÿæˆè¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = args.output_dir
    else:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = f"./local_btp_results/{args.model_config}_{args.experiment_size}_{timestamp}"
    
    # æ˜¾ç¤ºé…ç½®
    print("=" * 80)
    print("ğŸš€ æœ¬åœ°BTPå®éªŒå¯åŠ¨")
    print("=" * 80)
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®: {args.model_config} - {model_config['description']}")
    print(f"ğŸ“Š å®éªŒè§„æ¨¡: {args.experiment_size} - {experiment_preset['description']}")
    print()
    print("ğŸ”§ è¯¦ç»†é…ç½®:")
    print(f"  ğŸ“Š æºæ¨¡å‹: {source_model}")
    print(f"  ğŸ¯ ç›®æ ‡æ¨¡å‹: {target_model}")
    print(f"  ğŸ“‹ é—®é¢˜æ•°é‡: {max_problems}")
    print(f"  ğŸ” Beamæ•°é‡: {num_beams}")
    print(f"  ğŸ”„ è¿­ä»£æ¬¡æ•°: {n_iterations}")
    print(f"  ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"  ğŸ² é‡‡æ ·æ–¹æ³•: {args.sampling_method} (Î±={args.sampling_alpha})")
    print(f"  âš–ï¸ P2Valueæƒé‡: {args.p2value_alpha}")
    print(f"  ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 80)
    
    if args.dry_run:
        print("ğŸ” Dry runæ¨¡å¼ï¼Œä¸æ‰§è¡Œå®éªŒ")
        return
    
    # è¯¢é—®ç¡®è®¤
    response = input("æ˜¯å¦ç»§ç»­æ‰§è¡Œå®éªŒï¼Ÿ(y/N): ")
    if response.lower() not in ['y', 'yes']:
        print("âŒ å®éªŒå·²å–æ¶ˆ")
        return
    
    # LoRAé…ç½®
    lora_config = {
        'r': 32,
        'lora_alpha': 64,
        'lora_dropout': 0.05,
        'target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],
        'bias': 'none',
        'task_type': 'CAUSAL_LM'
    }
    
    # åˆ›å»ºè®­ç»ƒå‚æ•°
    training_args = create_optimized_training_args(
        f"{output_dir}/checkpoints", 
        args.experiment_size
    )
    
    # åˆ›å»ºå®éªŒ
    print("\nğŸ”„ åˆå§‹åŒ–å®éªŒ...")
    experiment = LocalBTPFineTuneExperiment(
        source_model_path=source_model,
        target_model_path=target_model,
        dataset="mbpp",
        sampling_method=args.sampling_method,
        sampling_alpha=args.sampling_alpha,
        p2value_alpha=args.p2value_alpha,
        use_lora=True,
        lora_config=lora_config
    )
    
    # è¿è¡Œå®éªŒ
    print("\nğŸš€ å¼€å§‹å®éªŒ...")
    results = experiment.run_experiment(
        max_problems=max_problems,
        num_beams=num_beams,
        n_iterations=n_iterations,
        batch_size=batch_size,
        output_dir=output_dir
    )
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸ“Š å®éªŒç»“æœæ‘˜è¦")
    print("=" * 80)
    final_stats = results['final_stats']
    initial_stats = results['initial_stats']
    
    print(f"ğŸ“ˆ ç»éªŒæ•°æ®:")
    print(f"  æ€»ç»éªŒæ•°: {final_stats.get('total_experiences', 0)}")
    print(f"  å®Œç¾è§£å†³æ–¹æ¡ˆ: {final_stats.get('perfect_solutions', 0)}")
    print(f"  å¹³å‡é€šè¿‡ç‡: {final_stats.get('avg_pass_rate', 0):.3f}")
    print(f"  å¹³å‡P2Value: {final_stats.get('avg_p2value', 0):.3f}")
    
    if initial_stats.get('total_experiences', 0) > 0:
        improvement = (final_stats.get('avg_pass_rate', 0) - initial_stats.get('avg_pass_rate', 0))
        print(f"  é€šè¿‡ç‡æå‡: {improvement:.3f}")
    
    print(f"\nğŸ“ è¯¦ç»†ç»“æœä¿å­˜åœ¨: {output_dir}")
    print("ğŸ‰ å®éªŒå®Œæˆ!")


if __name__ == "__main__":
    main() 