#!/usr/bin/env python3
"""
MBPPæ•°æ®é›†çš„BTPå®éªŒ (Beam Search + Testing + Prioritized Experience Replay)

BTPç®—æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š
1. é˜¶æ®µ1: Beam Searché‡‡æ · + æµ‹è¯•éªŒè¯
2. é˜¶æ®µ2: ä¼˜å…ˆç»éªŒå›æ”¾ (PPER) è®­ç»ƒ

æ”¯æŒçš„åŠŸèƒ½ï¼š
- æœ¬åœ°æ¨¡å‹çš„BTPå®éªŒ
- æœ¬åœ°æ¨¡å‹çš„BTPå¾®è°ƒå®éªŒ  
- OpenAI APIçš„BTPå®éªŒ
- DeepSeek APIçš„BTPå®éªŒ

ä½¿ç”¨ç¤ºä¾‹ï¼š
1. æœ¬åœ°æ¨¡å‹BTPå®éªŒï¼š
   python experiments/mbpp/step2_btp_experiment.py --model deepseek-ai/deepseek-coder-1.3b-instruct --mode local

2. æœ¬åœ°æ¨¡å‹å¾®è°ƒï¼š
   python experiments/mbpp/step2_btp_experiment.py --model deepseek-ai/deepseek-coder-1.3b-instruct --target-model deepseek-ai/deepseek-coder-1.3b-instruct --mode finetune

3. OpenAIå®éªŒï¼š
   python experiments/mbpp/step2_btp_experiment.py --model gpt-4 --mode openai --api-key YOUR_KEY
"""

import os
import sys
import json
import argparse
import numpy as np
import random
import torch
import math
import logging
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict, deque
from datetime import datetime
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

# å¯¼å…¥å…±äº«åŸºç¡€ç±»
from experiments.shared.base_experiment import Step2BTPExperiment  
from experiments.shared.dataset_configs import MBPP_CONFIG
from experiments.shared.common_utils import safe_execute_code, load_mbpp_problems

# æ¡ä»¶å¯¼å…¥
try:
    from transformers import (
        AutoModelForCausalLM, 
        AutoTokenizer, 
        Trainer, 
        TrainingArguments,
        DataCollatorForLanguageModeling
    )
    from peft import LoraConfig, get_peft_model, TaskType
    from datasets import Dataset
    HF_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  ç¼ºå°‘HuggingFaceä¾èµ–: {e}")
    HF_AVAILABLE = False

try:
    from eg_cfg.openai_utils import OpenAIClient, OpenAIInferenceError
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

# é¡¹ç›®ç›¸å…³å¯¼å…¥
from eg_cfg.mbpp_utils import run_tests
if HF_AVAILABLE:
    from eg_cfg.model_utils import setup_device, load_model, load_tokenizer


class ModelAdapter:
    """ç»Ÿä¸€æ¨¡å‹é€‚é…å™¨ - æ”¯æŒæœ¬åœ°å’ŒAPIæ¨¡å‹"""
    
    def __init__(self, model_name: str, model_type: str = "local", 
                 api_key: str = None, api_base: str = None, **kwargs):
        self.model_name = model_name
        self.model_type = model_type
        self.api_key = api_key
        self.api_base = api_base
        self.kwargs = kwargs
        
        self.model = None
        self.tokenizer = None
        self.device = None
        self._setup_model()
    
    def _setup_model(self):
        """è®¾ç½®æ¨¡å‹"""
        if self.model_type == "local":
            self._setup_local_model()
        elif self.model_type == "openai":
            self._setup_openai_model()
        elif self.model_type in ["deepseek", "api"]:
            self._setup_api_model()
    
    def _setup_local_model(self):
        """è®¾ç½®æœ¬åœ°æ¨¡å‹"""
        if not HF_AVAILABLE:
            raise ImportError("æœ¬åœ°æ¨¡å‹éœ€è¦å®‰è£…transformersåº“")
        
        print(f"ğŸ”§ åŠ è½½æœ¬åœ°æ¨¡å‹: {self.model_name}")
        self.device = setup_device()
        self.model, self.tokenizer = load_model(self.model_name, self.device)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
    
    def _setup_openai_model(self):
        """è®¾ç½®OpenAIæ¨¡å‹"""
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAIæ¨¡å‹éœ€è¦å®‰è£…openaiç›¸å…³ä¾èµ–")
        
        print(f"ğŸ”§ é…ç½®OpenAIæ¨¡å‹: {self.model_name}")
        self.client = OpenAIClient(api_key=self.api_key, model=self.model_name)
    
    def _setup_api_model(self):
        """è®¾ç½®APIæ¨¡å‹"""
        if not REQUESTS_AVAILABLE:
            raise ImportError("APIæ¨¡å‹éœ€è¦å®‰è£…requestsåº“")
        
        print(f"ğŸ”§ é…ç½®APIæ¨¡å‹: {self.model_name}")
        self.api_headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
    
    def generate(self, prompt: str, **generation_kwargs) -> List[Dict]:
        """ç»Ÿä¸€ç”Ÿæˆæ¥å£"""
        if self.model_type == "local":
            return self._generate_local(prompt, **generation_kwargs)
        elif self.model_type == "openai":
            return self._generate_openai(prompt, **generation_kwargs)
        elif self.model_type in ["deepseek", "api"]:
            return self._generate_api(prompt, **generation_kwargs)
    
    def _generate_local(self, prompt: str, num_beams: int = 5, 
                       temperature: float = 0.8, max_tokens: int = 512,
                       **kwargs) -> List[Dict]:
        """æœ¬åœ°æ¨¡å‹ç”Ÿæˆ"""
        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                num_beams=num_beams,
                num_return_sequences=num_beams,
                max_new_tokens=max_tokens,
                do_sample=temperature > 0,
                temperature=temperature if temperature > 0 else 1.0,
                return_dict_in_generate=True,
                output_scores=True,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
                **kwargs
            )
        
        results = []
        sequences = outputs.sequences
        scores = outputs.sequences_scores if hasattr(outputs, 'sequences_scores') else None
        
        for i, sequence in enumerate(sequences):
            generated_text = self.tokenizer.decode(sequence, skip_special_tokens=True)
            code = generated_text[len(prompt):].strip()
            
            if scores is not None:
                log_prob = scores[i].item()
                possibility = min(math.exp(log_prob / len(sequence)), 1.0)
            else:
                log_prob = -10.0
                possibility = 0.5
            
            results.append({
                'code': code,
                'possibility': possibility,
                'log_prob': log_prob,
                'beam_rank': i,
                'sequence_length': len(sequence) - inputs['input_ids'].shape[1]
            })
        
        return results
    
    def _generate_openai(self, prompt: str, num_beams: int = 5, 
                        temperature: float = 0.8, **kwargs) -> List[Dict]:
        """OpenAIæ¨¡å‹ç”Ÿæˆ"""
        results = []
        
        for i in range(num_beams):
            try:
                response = self.client.generate_completion(
                    prompt=prompt,
                    temperature=temperature,
                    max_tokens=512
                )
                
                results.append({
                    'code': response.get('content', ''),
                    'possibility': 0.8,  # OpenAIä¸æä¾›å…·ä½“æ¦‚ç‡
                    'log_prob': -5.0,
                    'beam_rank': i,
                    'sequence_length': len(response.get('content', ''))
                })
                
            except Exception as e:
                print(f"OpenAIç”Ÿæˆå¤±è´¥ (beam {i}): {e}")
                results.append({
                    'code': '',
                    'possibility': 0.0,
                    'log_prob': -100.0,
                    'beam_rank': i,
                    'sequence_length': 0,
                    'error': str(e)
                })
        
        return results
    
    def _generate_api(self, prompt: str, num_beams: int = 5, 
                     temperature: float = 0.8, **kwargs) -> List[Dict]:
        """APIæ¨¡å‹ç”Ÿæˆ"""
        results = []
        
        for i in range(num_beams):
            try:
                payload = {
                    "model": self.model_name,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": 512
                }
                
                response = requests.post(
                    self.api_base or "https://api.deepseek.com/v1/chat/completions",
                    headers=self.api_headers,
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data['choices'][0]['message']['content']
                    
                    results.append({
                        'code': content,
                        'possibility': 0.7,
                        'log_prob': -8.0,
                        'beam_rank': i,
                        'sequence_length': len(content)
                    })
                else:
                    raise Exception(f"APIé”™è¯¯: {response.status_code}")
                    
            except Exception as e:
                print(f"APIç”Ÿæˆå¤±è´¥ (beam {i}): {e}")
                results.append({
                    'code': '',
                    'possibility': 0.0,
                    'log_prob': -100.0,
                    'beam_rank': i,
                    'sequence_length': 0,
                    'error': str(e)
                })
        
        return results


class P2ValueCalculator:
    """P2Valueè®¡ç®—å™¨ - ç»“åˆå¯èƒ½æ€§å’Œé€šè¿‡ç‡"""
    
    def __init__(self, alpha: float = 0.5):
        self.alpha = alpha
    
    def calculate_p2value(self, possibility: float, pass_rate: float) -> float:
        """è®¡ç®—P2Value = Î± * possibility + (1-Î±) * pass_rate"""
        return self.alpha * possibility + (1 - self.alpha) * pass_rate
    
    def calculate_p2value_extended(self, log_prob=None, sequence_length=None, 
                                 possibility=None, passed_tests=0, total_tests=1):
        """æ‰©å±•P2Valueè®¡ç®—ï¼Œè€ƒè™‘æ›´å¤šå› ç´ """
        if possibility is None and log_prob is not None:
            possibility = min(math.exp(log_prob / max(sequence_length, 1)), 1.0)
        
        pass_rate = passed_tests / max(total_tests, 1)
        
        if possibility is None:
            possibility = 0.5
        
        return self.calculate_p2value(possibility, pass_rate)


class PrioritizedSampler:
    """ä¼˜å…ˆé‡‡æ ·å™¨ - åŸºäºP2Valueè¿›è¡Œé‡‡æ ·"""
    
    def __init__(self, sampling_method: str = "power", alpha: float = 1.0):
        self.sampling_method = sampling_method
        self.alpha = alpha
        
        if sampling_method not in ["power", "rank"]:
            raise ValueError(f"ä¸æ”¯æŒçš„é‡‡æ ·æ–¹æ³•: {sampling_method}")
    
    def sample(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """é‡‡æ ·ç»éªŒ"""
        if len(experiences) <= batch_size:
            return experiences
        
        if self.sampling_method == "power":
            return self._power_sampling(experiences, batch_size)
        elif self.sampling_method == "rank":
            return self._rank_sampling(experiences, batch_size)
    
    def _power_sampling(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """å¹‚é‡‡æ ·"""
        # è®¡ç®—æƒé‡
        weights = []
        for exp in experiences:
            p2value = exp.get('p2value', 0.0)
            weight = max(p2value ** self.alpha, 1e-8)
            weights.append(weight)
        
        weights = np.array(weights)
        probabilities = weights / weights.sum()
        
        # é‡‡æ ·ç´¢å¼•
        indices = np.random.choice(
            len(experiences), 
            size=batch_size, 
            replace=False, 
            p=probabilities
        )
        
        return [experiences[i] for i in indices]
    
    def _rank_sampling(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """æ’åºé‡‡æ ·"""
        # æŒ‰P2Valueæ’åº
        sorted_experiences = sorted(
            experiences, 
            key=lambda x: x.get('p2value', 0.0), 
            reverse=True
        )
        
        # è®¡ç®—æ’åºæƒé‡
        weights = [1.0 / (rank + 1) ** self.alpha for rank in range(len(sorted_experiences))]
        weights = np.array(weights)
        probabilities = weights / weights.sum()
        
        # é‡‡æ ·
        indices = np.random.choice(
            len(sorted_experiences), 
            size=batch_size, 
            replace=False, 
            p=probabilities
        )
        
        return [sorted_experiences[i] for i in indices]


class ExperienceReplayBuffer:
    """ç»éªŒå›æ”¾ç¼“å†²åŒº"""
    
    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self.experiences = deque(maxlen=max_size)
        self.p2calculator = P2ValueCalculator()
    
    def add_experience(self, experience: Dict):
        """æ·»åŠ ç»éªŒ"""
        # è®¡ç®—P2Value
        experience['p2value'] = self.p2calculator.calculate_p2value_extended(
            possibility=experience.get('possibility', 0.5),
            passed_tests=experience.get('passed_tests', 0),
            total_tests=experience.get('total_tests', 1)
        )
        
        self.experiences.append(experience)
    
    def get_all_experiences(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ç»éªŒ"""
        return list(self.experiences)
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.experiences:
            return {}
        
        p2values = [exp.get('p2value', 0.0) for exp in self.experiences]
        pass_rates = [exp.get('pass_rate', 0.0) for exp in self.experiences]
        
        return {
            'total_experiences': len(self.experiences),
            'avg_p2value': np.mean(p2values),
            'max_p2value': np.max(p2values), 
            'min_p2value': np.min(p2values),
            'avg_pass_rate': np.mean(pass_rates),
            'fully_passed_count': sum(1 for pr in pass_rates if pr >= 1.0),
            'zero_passed_count': sum(1 for pr in pass_rates if pr == 0.0)
        }


class MBTPFineTuningManager:
    """MBPP BTPå¾®è°ƒç®¡ç†å™¨"""
    
    def __init__(self, model_adapter: ModelAdapter, use_lora: bool = True, 
                 lora_config: Optional[Dict] = None):
        self.model_adapter = model_adapter
        self.use_lora = use_lora
        self.lora_config = lora_config or {
            'r': 16,
            'lora_alpha': 32,
            'lora_dropout': 0.1
        }
        
        if self.use_lora and HF_AVAILABLE:
            self._setup_lora()
    
    def _setup_lora(self):
        """è®¾ç½®LoRAå¾®è°ƒ"""
        if self.model_adapter.model_type != "local":
            print("âš ï¸  LoRAå¾®è°ƒä»…æ”¯æŒæœ¬åœ°æ¨¡å‹")
            return
        
        lora_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            r=self.lora_config['r'],
            lora_alpha=self.lora_config['lora_alpha'],
            lora_dropout=self.lora_config['lora_dropout'],
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]
        )
        
        self.model_adapter.model = get_peft_model(self.model_adapter.model, lora_config)
        print("âœ… LoRAé…ç½®å®Œæˆ")
    
    def finetune_on_experiences(self, experiences: List[Dict], 
                               training_args: Optional[TrainingArguments] = None) -> None:
        """åŸºäºç»éªŒè¿›è¡Œå¾®è°ƒ"""
        if self.model_adapter.model_type != "local":
            print("âš ï¸  å¾®è°ƒä»…æ”¯æŒæœ¬åœ°æ¨¡å‹")
            return
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        train_dataset = self._prepare_training_dataset(experiences)
        
        if training_args is None:
            training_args = TrainingArguments(
                output_dir="./mbpp_btp_checkpoints",
                num_train_epochs=1,
                per_device_train_batch_size=2,
                gradient_accumulation_steps=4,
                warmup_steps=10,
                learning_rate=1e-4,
                fp16=True,
                logging_steps=5,
                save_steps=100,
                remove_unused_columns=False,
            )
        
        # æ•°æ®æ•´ç†å™¨
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.model_adapter.tokenizer,
            mlm=False,
        )
        
        # è®­ç»ƒå™¨
        trainer = Trainer(
            model=self.model_adapter.model,
            args=training_args,
            train_dataset=train_dataset,
            data_collator=data_collator,
        )
        
        print("ğŸš€ å¼€å§‹å¾®è°ƒ...")
        trainer.train()
        trainer.save_model()
        print("âœ… å¾®è°ƒå®Œæˆ")
    
    def _prepare_training_dataset(self, experiences: List[Dict]) -> Dataset:
        """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
        texts = []
        
        for exp in experiences:
            instruction = f"Solve this programming problem:\n{exp['problem_text']}"
            response = exp['code']
            
            text = f"### Instruction:\n{instruction}\n\n### Response:\n{response}{self.model_adapter.tokenizer.eos_token}"
            texts.append(text)
        
        def tokenize_function(examples):
            if isinstance(examples['text'], str):
                examples['text'] = [examples['text']]
            
            tokenized = self.model_adapter.tokenizer(
                examples['text'],
                truncation=True,
                padding=True,
                max_length=1024,
                return_tensors="pt"
            )
            
            tokenized["labels"] = tokenized["input_ids"].clone()
            return tokenized
        
        dataset = Dataset.from_dict({'text': texts})
        tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=['text'])
        
        return tokenized_dataset


class MBBPBTPExperiment(Step2BTPExperiment):
    """MBPPæ•°æ®é›†çš„BTPå®éªŒ"""
    
    def __init__(self, model_name: str, mode: str = "local", api_key: str = None,
                 target_model: str = None, sampling_method: str = "power",
                 sampling_alpha: float = 1.0, p2value_alpha: float = 0.5):
        
        # åˆå§‹åŒ–åŸºç±»
        super().__init__("mbpp", model_name)
        
        # BTPç‰¹å®šå‚æ•°
        self.mode = mode
        self.api_key = api_key
        self.target_model = target_model
        self.sampling_method = sampling_method
        self.sampling_alpha = sampling_alpha
        self.p2value_alpha = p2value_alpha
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_model_adapter()
        self.experience_buffer = ExperienceReplayBuffer()
        self.sampler = PrioritizedSampler(sampling_method, sampling_alpha)
        self.p2calculator = P2ValueCalculator(p2value_alpha)
        
        # å¾®è°ƒç®¡ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if mode == "finetune":
            self.finetuning_manager = MBTPFineTuningManager(self.model_adapter, use_lora=True)
        else:
            self.finetuning_manager = None
    
    def _setup_model_adapter(self):
        """è®¾ç½®æ¨¡å‹é€‚é…å™¨"""
        if self.mode == "openai":
            self.model_adapter = ModelAdapter(
                self.model_name, 
                model_type="openai", 
                api_key=self.api_key
            )
        elif self.mode in ["deepseek", "api"]:
            self.model_adapter = ModelAdapter(
                self.model_name, 
                model_type="api", 
                api_key=self.api_key
            )
        else:  # local or finetune
            self.model_adapter = ModelAdapter(
                self.model_name, 
                model_type="local"
            )
    
    def load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """åŠ è½½MBPPé…ç½®"""
        return MBPP_CONFIG
    
    def load_dataset(self) -> Dict[str, Any]:
        """åŠ è½½MBPPæ•°æ®é›†"""
        return load_mbpp_problems()
    
    def format_prompt(self, problem: Dict[str, Any]) -> str:
        """ä½¿ç”¨è‹±æ–‡æç¤ºæ¨¡æ¿æ ¼å¼åŒ–é—®é¢˜"""
        return self.config['prompt_template'].format(
            problem_text=problem['text'],
            test_examples="\n".join([f"  {test}" for test in problem.get('test_list', [])])
        )
    
    def phase1_beam_search_sampling(self, problems_list: List[tuple], num_beams: int):
        """é˜¶æ®µ1: Beam Searché‡‡æ ·"""
        print("ğŸ” é˜¶æ®µ1: Beam Searché‡‡æ ·")
        
        for task_id, problem in tqdm(problems_list, desc="Beam Searché‡‡æ ·"):
            prompt = self.format_prompt(problem)
            
            try:
                # ç”Ÿæˆå€™é€‰è§£
                candidates = self.model_adapter.generate(
                    prompt, 
                    num_beams=num_beams,
                    temperature=0.8,
                    max_tokens=512
                )
                
                # æµ‹è¯•æ¯ä¸ªå€™é€‰è§£
                for candidate in candidates:
                    code = candidate['code']
                    if not code.strip():
                        continue
                    
                    try:
                        # è¿è¡Œæµ‹è¯•
                        test_results = run_tests(code, problem['test_list'])
                        passed_tests = sum(1 for r in test_results.values() if r.get('result', False))
                        total_tests = len(test_results)
                        pass_rate = passed_tests / total_tests if total_tests > 0 else 0.0
                        
                        experience = {
                            'problem_id': str(task_id),
                            'problem_text': problem['text'],
                            'code': code,
                            'possibility': candidate['possibility'],
                            'pass_rate': pass_rate,
                            'passed_tests': passed_tests,
                            'total_tests': total_tests,
                            'test_results': test_results,
                            'beam_rank': candidate['beam_rank']
                        }
                        
                        self.experience_buffer.add_experience(experience)
                        
                    except Exception as e:
                        # æµ‹è¯•å¤±è´¥ä¹Ÿè¦è®°å½•
                        experience = {
                            'problem_id': str(task_id),
                            'problem_text': problem['text'],
                            'code': code,
                            'possibility': candidate['possibility'],
                            'pass_rate': 0.0,
                            'passed_tests': 0,
                            'total_tests': len(problem.get('test_list', [])),
                            'error': str(e),
                            'beam_rank': candidate['beam_rank']
                        }
                        self.experience_buffer.add_experience(experience)
                        
            except Exception as e:
                print(f"âš ï¸  é—®é¢˜ {task_id} ç”Ÿæˆå¤±è´¥: {e}")
                continue
    
    def phase2_pper_training(self, n_iterations: int, batch_size: int):
        """é˜¶æ®µ2: ä¼˜å…ˆç»éªŒå›æ”¾è®­ç»ƒ"""
        print(f"ğŸ¯ é˜¶æ®µ2: ä¼˜å…ˆç»éªŒå›æ”¾è®­ç»ƒ ({n_iterations} è½®è¿­ä»£)")
        
        if self.finetuning_manager is None:
            print("âš ï¸  è·³è¿‡å¾®è°ƒé˜¶æ®µï¼ˆå½“å‰æ¨¡å¼ä¸æ”¯æŒå¾®è°ƒï¼‰")
            return
        
        for iteration in range(n_iterations):
            print(f"\nğŸ“ˆ è¿­ä»£ {iteration + 1}/{n_iterations}")
            
            # è·å–æ‰€æœ‰ç»éªŒ
            all_experiences = self.experience_buffer.get_all_experiences()
            if len(all_experiences) == 0:
                print("âš ï¸  æ²¡æœ‰å¯ç”¨ç»éªŒï¼Œè·³è¿‡æ­¤è½®è¿­ä»£")
                continue
            
            # ä¼˜å…ˆé‡‡æ ·
            sampled_experiences = self.sampler.sample(all_experiences, batch_size)
            print(f"ğŸ“Š é‡‡æ ·äº† {len(sampled_experiences)} ä¸ªç»éªŒç”¨äºè®­ç»ƒ")
            
            # æ‰§è¡Œå¾®è°ƒ
            try:
                self.finetuning_manager.finetune_on_experiences(sampled_experiences)
                print(f"âœ… è¿­ä»£ {iteration + 1} å¾®è°ƒå®Œæˆ")
            except Exception as e:
                print(f"âŒ è¿­ä»£ {iteration + 1} å¾®è°ƒå¤±è´¥: {e}")
                continue
    
    def get_experiment_results(self) -> Dict[str, Any]:
        """è·å–å®éªŒç»“æœ"""
        stats = self.experience_buffer.get_stats()
        
        results = {
            'experiment_type': 'MBPP_BTP',
            'model_name': self.model_name,
            'mode': self.mode,
            'target_model': self.target_model,
            'sampling_method': self.sampling_method,
            'sampling_alpha': self.sampling_alpha,
            'p2value_alpha': self.p2value_alpha,
            'experience_stats': stats,
            'config': self.get_experiment_config()
        }
        
        return results


def main():
    parser = argparse.ArgumentParser(
        description='MBPPæ•°æ®é›†çš„BTPå®éªŒ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. æœ¬åœ°æ¨¡å‹BTPå®éªŒ:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model deepseek-ai/deepseek-coder-1.3b-instruct \\
     --mode local --max-problems 50

2. æœ¬åœ°æ¨¡å‹å¾®è°ƒ:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model deepseek-ai/deepseek-coder-1.3b-instruct \\
     --mode finetune --max-problems 100

3. OpenAIå®éªŒ:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model gpt-4 --mode openai \\
     --api-key YOUR_KEY --max-problems 30

4. DeepSeek APIå®éªŒ:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model deepseek-chat --mode deepseek \\
     --api-key YOUR_KEY --max-problems 30
        """)
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--model', type=str, required=True,
                       help='æ¨¡å‹åç§°æˆ–è·¯å¾„')
    parser.add_argument('--mode', type=str, default='local',
                       choices=['local', 'finetune', 'openai', 'deepseek'],
                       help='å®éªŒæ¨¡å¼')
    parser.add_argument('--target-model', type=str, default=None,
                       help='ç›®æ ‡å¾®è°ƒæ¨¡å‹ï¼ˆä»…å¾®è°ƒæ¨¡å¼éœ€è¦ï¼‰')
    
    # APIå‚æ•°
    parser.add_argument('--api-key', type=str,
                       help='APIå¯†é’¥')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--max-problems', type=int, default=50,
                       help='æœ€å¤§é—®é¢˜æ•°é‡')
    parser.add_argument('--num-beams', type=int, default=5,
                       help='Beam Searchæ•°é‡')
    parser.add_argument('--n-iterations', type=int, default=2,
                       help='PPERè®­ç»ƒè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--batch-size', type=int, default=50,
                       help='è®­ç»ƒæ‰¹å¤§å°')
    
    # BTPç®—æ³•å‚æ•°
    parser.add_argument('--sampling-method', type=str, default='power',
                       choices=['power', 'rank'],
                       help='é‡‡æ ·æ–¹æ³•')
    parser.add_argument('--sampling-alpha', type=float, default=1.0,
                       help='é‡‡æ ·Î±å‚æ•°')
    parser.add_argument('--p2value-alpha', type=float, default=0.5,
                       help='P2Valueæƒé‡Î±')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ—¥å¿—')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.DEBUG if args.debug else logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)
    
    # æ‰“å°é…ç½®
    print("ğŸš€ MBPP BTPå®éªŒé…ç½®:")
    print(f"  æ¨¡å‹: {args.model}")
    print(f"  æ¨¡å¼: {args.mode}")
    print(f"  æœ€å¤§é—®é¢˜æ•°: {args.max_problems}")
    print(f"  é‡‡æ ·æ–¹æ³•: {args.sampling_method}")
    print(f"  é‡‡æ ·Alpha: {args.sampling_alpha}")
    print(f"  P2Value Alpha: {args.p2value_alpha}")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = MBBPBTPExperiment(
        model_name=args.model,
        mode=args.mode,
        api_key=args.api_key,
        target_model=args.target_model,
        sampling_method=args.sampling_method,
        sampling_alpha=args.sampling_alpha,
        p2value_alpha=args.p2value_alpha
    )
    
    # è¿è¡Œå®éªŒ
    try:
        results = experiment.run_experiment(
            max_problems=args.max_problems,
            num_beams=args.num_beams,
            n_iterations=args.n_iterations,
            batch_size=args.batch_size
        )
        
        # ä¿å­˜ç»“æœ
        result_file = experiment.save_results(results, "btp_experiment")
        
        print("\nâœ… å®éªŒå®Œæˆ!")
        print(f"ğŸ“Š å®éªŒç»Ÿè®¡:")
        for key, value in results['experience_stats'].items():
            print(f"  {key}: {value}")
        
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        return 0
        
    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main()) 