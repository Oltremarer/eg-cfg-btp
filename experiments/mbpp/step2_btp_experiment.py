#!/usr/bin/env python3
"""
MBPPæ•°æ®é›†çš„BTPå®éªŒ (Beam Search + Testing + Prioritized Experience Replay)

BTPç®—æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š
1. é˜¶æ®µ1: Beam Searché‡‡æ · + æµ‹è¯•éªŒè¯
2. é˜¶æ®µ2: ä¼˜å…ˆç»éªŒå›æ”¾ (PPER) è®­ç»ƒ

æ”¯æŒçš„åŠŸèƒ½ï¼š
- æœ¬åœ°æ¨¡å‹çš„BTPå®éªŒ
- æœ¬åœ°æ¨¡å‹çš„BTPå¾®è°ƒå®éªŒ  
- OpenAI APIçš„BTPå®éªŒ
- DeepSeek APIçš„BTPå®éªŒ

ä½¿ç”¨ç¤ºä¾‹ï¼š
1. æœ¬åœ°æ¨¡å‹BTPå®éªŒï¼š
   python experiments/mbpp/step2_btp_experiment.py --model deepseek-ai/deepseek-coder-1.3b-instruct --mode local

2. æœ¬åœ°æ¨¡å‹å¾®è°ƒï¼š
   python experiments/mbpp/step2_btp_experiment.py --model deepseek-ai/deepseek-coder-1.3b-instruct --target-model deepseek-ai/deepseek-coder-1.3b-instruct --mode finetune

3. OpenAIå®éªŒï¼š
   python experiments/mbpp/step2_btp_experiment.py --model gpt-4 --mode openai --api-key YOUR_KEY
"""

import os
import sys
import json
import argparse
import numpy as np
import random
import torch
import math
import logging
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict, deque
from datetime import datetime
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

# å¯¼å…¥å…±äº«åŸºç¡€ç±»
from experiments.shared.base_experiment import Step2BTPExperiment  
from experiments.shared.dataset_configs import MBPP_CONFIG
from experiments.shared.common_utils import safe_execute_code, load_mbpp_problems

# æ¡ä»¶å¯¼å…¥
try:
    from transformers import (
        AutoModelForCausalLM, 
        AutoTokenizer, 
        Trainer, 
        TrainingArguments,
        DataCollatorForLanguageModeling
    )
    from peft import LoraConfig, get_peft_model, TaskType
    from datasets import Dataset
    HF_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  ç¼ºå°‘HuggingFaceä¾èµ–: {e}")
    HF_AVAILABLE = False

try:
    from eg_cfg.openai_utils import OpenAIClient, OpenAIInferenceError
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

# é¡¹ç›®ç›¸å…³å¯¼å…¥
from eg_cfg.mbpp_utils import run_tests
if HF_AVAILABLE:
    from eg_cfg.model_utils import setup_device, load_model, load_tokenizer

from experiments.prompt_templates import get_model_prompt, detect_model_info, validate_model_compatibility
from experiments.shared.model_configs import get_model_config, get_optimal_generation_params


class ModelAdapter:
    """ç»Ÿä¸€æ¨¡å‹é€‚é…å™¨ - æ”¯æŒæœ¬åœ°å’ŒAPIæ¨¡å‹"""
    
    def __init__(self, model_name: str, model_type: str = "local", 
                 api_key: str = None, api_base: str = None, **kwargs):
        self.model_name = model_name
        self.model_type = model_type
        self.api_key = api_key
        self.api_base = api_base
        self.kwargs = kwargs
        
        self.model = None
        self.tokenizer = None
        self.device = None
        self._setup_model()
    
    def _setup_model(self):
        """è®¾ç½®æ¨¡å‹"""
        if self.model_type == "local" or self.model_type == "finetune":
            self._setup_local_model()
        elif self.model_type == "openai":
            self._setup_openai_model()
        elif self.model_type in ["deepseek", "api"]:
            self._setup_api_model()
    
    def _setup_local_model(self):
        """è®¾ç½®æœ¬åœ°æ¨¡å‹"""
        if not HF_AVAILABLE:
            raise ImportError("æœ¬åœ°æ¨¡å‹éœ€è¦å®‰è£…transformersåº“")
        
        print(f"ğŸ”§ åŠ è½½æœ¬åœ°æ¨¡å‹: {self.model_name}")
        self.device = setup_device()
        self.model, self.tokenizer = load_model(self.model_name, self.device)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
    
    def _setup_openai_model(self):
        """è®¾ç½®OpenAIæ¨¡å‹"""
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAIæ¨¡å‹éœ€è¦å®‰è£…openaiç›¸å…³ä¾èµ–")
        
        print(f"ğŸ”§ é…ç½®OpenAIæ¨¡å‹: {self.model_name}")
        self.client = OpenAIClient(api_key=self.api_key, model=self.model_name)
    
    def _setup_api_model(self):
        """è®¾ç½®APIæ¨¡å‹"""
        if not REQUESTS_AVAILABLE:
            raise ImportError("APIæ¨¡å‹éœ€è¦å®‰è£…requestsåº“")
        
        print(f"ğŸ”§ é…ç½®APIæ¨¡å‹: {self.model_name}")
        self.api_headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
    
    def generate(self, prompt: str, **generation_kwargs) -> List[Dict]:
        """ç»Ÿä¸€ç”Ÿæˆæ¥å£"""
        if self.model_type == "local" or self.model_type == "finetune":
            return self._generate_local(prompt, **generation_kwargs)
        elif self.model_type == "openai":
            return self._generate_openai(prompt, **generation_kwargs)
        elif self.model_type in ["deepseek", "api"]:
            return self._generate_api(prompt, **generation_kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    def _generate_local(self, prompt: str, num_beams: int = 5, 
                       temperature: float = 0.8, max_tokens: int = 512,
                       **kwargs) -> List[Dict]:
        """æœ¬åœ°æ¨¡å‹ç”Ÿæˆ"""
        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                num_beams=num_beams,
                num_return_sequences=num_beams,
                max_new_tokens=max_tokens,
                do_sample=temperature > 0,
                temperature=temperature if temperature > 0 else 1.0,
                return_dict_in_generate=True,
                output_scores=True,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
                **kwargs
            )
        
        results = []
        sequences = outputs.sequences
        scores = outputs.sequences_scores if hasattr(outputs, 'sequences_scores') else None
        
        for i, sequence in enumerate(sequences):
            generated_text = self.tokenizer.decode(sequence, skip_special_tokens=True)
            code = generated_text[len(prompt):].strip()
            
            if scores is not None:
                log_prob = scores[i].item()
                possibility = min(math.exp(log_prob / len(sequence)), 1.0)
            else:
                log_prob = -10.0
                possibility = 0.5
            
            results.append({
                'code': code,
                'possibility': possibility,
                'log_prob': log_prob,
                'beam_rank': i,
                'sequence_length': len(sequence) - inputs['input_ids'].shape[1]
            })
        
        return results
    
    def _generate_openai(self, prompt: str, num_beams: int = 5, 
                        temperature: float = 0.8, **kwargs) -> List[Dict]:
        """OpenAIæ¨¡å‹ç”Ÿæˆ"""
        results = []
        
        for i in range(num_beams):
            try:
                response = self.client.generate_completion(
                    prompt=prompt,
                    temperature=temperature,
                    max_tokens=512
                )
                
                results.append({
                    'code': response.get('content', ''),
                    'possibility': 0.8,  # OpenAIä¸æä¾›å…·ä½“æ¦‚ç‡
                    'log_prob': -5.0,
                    'beam_rank': i,
                    'sequence_length': len(response.get('content', ''))
                })
                
            except Exception as e:
                print(f"OpenAIç”Ÿæˆå¤±è´¥ (beam {i}): {e}")
                results.append({
                    'code': '',
                    'possibility': 0.0,
                    'log_prob': -100.0,
                    'beam_rank': i,
                    'sequence_length': 0,
                    'error': str(e)
                })
        
        return results
    
    def _generate_api(self, prompt: str, num_beams: int = 5, 
                     temperature: float = 0.8, **kwargs) -> List[Dict]:
        """APIæ¨¡å‹ç”Ÿæˆ"""
        results = []
        
        for i in range(num_beams):
            try:
                payload = {
                    "model": self.model_name,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": 512
                }
                
                response = requests.post(
                    self.api_base or "https://api.deepseek.com/v1/chat/completions",
                    headers=self.api_headers,
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data['choices'][0]['message']['content']
                    
                    results.append({
                        'code': content,
                        'possibility': 0.7,
                        'log_prob': -8.0,
                        'beam_rank': i,
                        'sequence_length': len(content)
                    })
                else:
                    raise Exception(f"APIé”™è¯¯: {response.status_code}")
                    
            except Exception as e:
                print(f"APIç”Ÿæˆå¤±è´¥ (beam {i}): {e}")
                results.append({
                    'code': '',
                    'possibility': 0.0,
                    'log_prob': -100.0,
                    'beam_rank': i,
                    'sequence_length': 0,
                    'error': str(e)
                })
        
        return results


class P2ValueCalculator:
    """P2Valueè®¡ç®—å™¨ - ç»“åˆå¯èƒ½æ€§å’Œé€šè¿‡ç‡"""
    
    def __init__(self, alpha: float = 0.5):
        self.alpha = alpha
    
    def calculate_p2value(self, possibility: float, pass_rate: float) -> float:
        """è®¡ç®—P2Value = Î± * possibility + (1-Î±) * pass_rate"""
        return self.alpha * possibility + (1 - self.alpha) * pass_rate
    
    def calculate_p2value_extended(self, log_prob=None, sequence_length=None, 
                                 possibility=None, passed_tests=0, total_tests=1):
        """æ‰©å±•P2Valueè®¡ç®—ï¼Œè€ƒè™‘æ›´å¤šå› ç´ """
        if possibility is None and log_prob is not None:
            possibility = min(math.exp(log_prob / max(sequence_length, 1)), 1.0)
        
        pass_rate = passed_tests / max(total_tests, 1)
        
        if possibility is None:
            possibility = 0.5
        
        return self.calculate_p2value(possibility, pass_rate)


class PrioritizedSampler:
    """ä¼˜å…ˆé‡‡æ ·å™¨ - åŸºäºP2Valueè¿›è¡Œé‡‡æ ·"""
    
    def __init__(self, sampling_method: str = "power", alpha: float = 1.0):
        self.sampling_method = sampling_method
        self.alpha = alpha
        
        if sampling_method not in ["power", "rank"]:
            raise ValueError(f"ä¸æ”¯æŒçš„é‡‡æ ·æ–¹æ³•: {sampling_method}")
    
    def sample(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """é‡‡æ ·ç»éªŒ"""
        if len(experiences) <= batch_size:
            return experiences
        
        if self.sampling_method == "power":
            return self._power_sampling(experiences, batch_size)
        elif self.sampling_method == "rank":
            return self._rank_sampling(experiences, batch_size)
    
    def _power_sampling(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """å¹‚é‡‡æ ·"""
        # è®¡ç®—æƒé‡
        weights = []
        for exp in experiences:
            p2value = exp.get('p2value', 0.0)
            weight = max(p2value ** self.alpha, 1e-8)
            weights.append(weight)
        
        weights = np.array(weights)
        probabilities = weights / weights.sum()
        
        # é‡‡æ ·ç´¢å¼•
        indices = np.random.choice(
            len(experiences), 
            size=batch_size, 
            replace=False, 
            p=probabilities
        )
        
        return [experiences[i] for i in indices]
    
    def _rank_sampling(self, experiences: List[Dict], batch_size: int) -> List[Dict]:
        """æ’åºé‡‡æ ·"""
        # æŒ‰P2Valueæ’åº
        sorted_experiences = sorted(
            experiences, 
            key=lambda x: x.get('p2value', 0.0), 
            reverse=True
        )
        
        # è®¡ç®—æ’åºæƒé‡
        weights = [1.0 / (rank + 1) ** self.alpha for rank in range(len(sorted_experiences))]
        weights = np.array(weights)
        probabilities = weights / weights.sum()
        
        # é‡‡æ ·
        indices = np.random.choice(
            len(sorted_experiences), 
            size=batch_size, 
            replace=False, 
            p=probabilities
        )
        
        return [sorted_experiences[i] for i in indices]


class ExperienceReplayBuffer:
    """ç»éªŒå›æ”¾ç¼“å†²åŒº"""
    
    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self.experiences = deque(maxlen=max_size)
        self.p2calculator = P2ValueCalculator()
    
    def add_experience(self, experience: Dict):
        """æ·»åŠ ç»éªŒ"""
        # è®¡ç®—P2Value
        experience['p2value'] = self.p2calculator.calculate_p2value_extended(
            possibility=experience.get('possibility', 0.5),
            passed_tests=experience.get('passed_tests', 0),
            total_tests=experience.get('total_tests', 1)
        )
        
        self.experiences.append(experience)
    
    def get_all_experiences(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ç»éªŒ"""
        return list(self.experiences)
    
    def get_stats(self, include_samples: bool = False, max_samples: int = 10) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.experiences:
            return {}
        
        p2values = [exp.get('p2value', 0.0) for exp in self.experiences]
        pass_rates = [exp.get('pass_rate', 0.0) for exp in self.experiences]
        
        stats = {
            'total_experiences': len(self.experiences),
            'avg_p2value': np.mean(p2values),
            'max_p2value': np.max(p2values), 
            'min_p2value': np.min(p2values),
            'avg_pass_rate': np.mean(pass_rates),
            'fully_passed_count': sum(1 for pr in pass_rates if pr >= 1.0),
            'zero_passed_count': sum(1 for pr in pass_rates if pr == 0.0)
        }
        
        # å¦‚æœéœ€è¦åŒ…å«æ ·æœ¬æ•°æ®ï¼Œæ·»åŠ ä¸€äº›ä»£è¡¨æ€§æ ·æœ¬
        if include_samples:
            samples = []
            
            # è·å–é€šè¿‡ç‡æœ€é«˜çš„æ ·æœ¬
            best_experiences = sorted(self.experiences, key=lambda x: x.get('pass_rate', 0), reverse=True)[:max_samples//2]
            samples.extend(best_experiences)
            
            # æ·»åŠ ä¸€äº›éšæœºæ ·æœ¬
            import random
            remaining_samples = max_samples - len(samples)
            if remaining_samples > 0 and len(self.experiences) > len(samples):
                random_experiences = random.sample(
                    [exp for exp in self.experiences if exp not in samples], 
                    min(remaining_samples, len(self.experiences) - len(samples))
                )
                samples.extend(random_experiences)
            
            stats['sample_experiences'] = samples
        
        return stats


class MBTPFineTuningManager:
    """MBPP BTPå¾®è°ƒç®¡ç†å™¨"""
    
    def __init__(self, model_adapter: ModelAdapter, use_lora: bool = True, 
                 lora_config: Optional[Dict] = None, output_dir: str = "./mbpp_btp_checkpoints"):
        self.model_adapter = model_adapter
        self.use_lora = use_lora
        self.output_dir = output_dir
        self.lora_config = lora_config or {
            'r': 16,
            'lora_alpha': 32,
            'lora_dropout': 0.1
        }
        
        if self.use_lora and HF_AVAILABLE:
            self._setup_lora()
    
    def _setup_lora(self):
        """è®¾ç½®LoRAå¾®è°ƒ"""
        if self.model_adapter.model_type not in ["local", "finetune"]:
            print("âš ï¸  LoRAå¾®è°ƒä»…æ”¯æŒæœ¬åœ°æ¨¡å‹")
            return
        
        lora_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            r=self.lora_config['r'],
            lora_alpha=self.lora_config['lora_alpha'],
            lora_dropout=self.lora_config['lora_dropout'],
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]
        )
        
        self.model_adapter.model = get_peft_model(self.model_adapter.model, lora_config)
        print("âœ… LoRAé…ç½®å®Œæˆ")
    
    def finetune_on_experiences(self, experiences: List[Dict], 
                               training_args: Optional[TrainingArguments] = None) -> None:
        """åŸºäºç»éªŒè¿›è¡Œå¾®è°ƒ"""
        if self.model_adapter.model_type not in ["local", "finetune"]:
            print("âš ï¸  å¾®è°ƒä»…æ”¯æŒæœ¬åœ°æ¨¡å‹")
            return
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        train_dataset = self._prepare_training_dataset(experiences)
        
        if training_args is None:
            training_args = TrainingArguments(
                output_dir=self.output_dir,  # ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•
                num_train_epochs=1,
                per_device_train_batch_size=2,
                gradient_accumulation_steps=4,
                warmup_steps=10,
                learning_rate=1e-6,  # å¤§å¹…å‡å°‘å­¦ä¹ ç‡ï¼Œä»1e-4æ”¹ä¸º1e-6
                fp16=True,
                logging_steps=5,
                save_steps=100,
                remove_unused_columns=False,
            )
        
        # æ•°æ®æ•´ç†å™¨
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.model_adapter.tokenizer,
            mlm=False,
        )
        
        # è®­ç»ƒå™¨
        trainer = Trainer(
            model=self.model_adapter.model,
            args=training_args,
            train_dataset=train_dataset,
            data_collator=data_collator,
        )
        
        print(f"ğŸš€ å¼€å§‹å¾®è°ƒ... æ¨¡å‹å°†ä¿å­˜åˆ°: {self.output_dir}")
        trainer.train()
        trainer.save_model()
        print("âœ… å¾®è°ƒå®Œæˆ")
    
    def _prepare_training_dataset(self, experiences: List[Dict]) -> Dataset:
        """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
        texts = []
        
        for exp in experiences:
            instruction = f"Solve this programming problem:\n{exp['problem_text']}"
            response = exp['code']
            
            text = f"### Instruction:\n{instruction}\n\n### Response:\n{response}{self.model_adapter.tokenizer.eos_token}"
            texts.append(text)
        
        def tokenize_function(examples):
            if isinstance(examples['text'], str):
                examples['text'] = [examples['text']]
            
            tokenized = self.model_adapter.tokenizer(
                examples['text'],
                truncation=True,
                padding=True,
                max_length=1024,
                return_tensors="pt"
            )
            
            tokenized["labels"] = tokenized["input_ids"].clone()
            return tokenized
        
        dataset = Dataset.from_dict({'text': texts})
        tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=['text'])
        
        return tokenized_dataset


class MBBPBTPExperiment(Step2BTPExperiment):
    """MBPPæ•°æ®é›†çš„BTPå®éªŒ - ä½¿ç”¨æ™ºèƒ½Prompté€‚é…ç³»ç»Ÿ"""
    
    def __init__(self, model_name: str = None, model_type: str = "local", 
                 api_key: str = None, api_base: str = None,
                 sampling_method: str = "power", sampling_alpha: float = 1.0, 
                 p2value_alpha: float = 0.5, output_dir: str = "./mbpp_btp_checkpoints"):
        
        # è®¾ç½®åŸºæœ¬æ¨¡å‹ä¿¡æ¯
        self.model_name = model_name or "deepseek-ai/deepseek-coder-1.3b-instruct"
        self.model_type = model_type
        self.api_key = api_key
        self.api_base = api_base
        self.output_dir = output_dir
        
        # BTPç‰¹å®šå‚æ•°  
        self.sampling_method = sampling_method
        self.sampling_alpha = sampling_alpha
        self.p2value_alpha = p2value_alpha
        
        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        super().__init__(dataset_name="mbpp", model_name=self.model_name)
        
        # åˆå§‹åŒ–æ™ºèƒ½é…ç½®ï¼ˆåœ¨çˆ¶ç±»æ„é€ å‡½æ•°ä¹‹åï¼‰
        self.model_info = detect_model_info(self.model_name)
        self.model_config = get_model_config(self.model_name)
        self.optimal_params = get_optimal_generation_params(self.model_name, "mbpp")
        
        # éªŒè¯æ¨¡å‹å…¼å®¹æ€§
        compatibility = validate_model_compatibility(self.model_name, "mbpp")
        if compatibility["warnings"]:
            print("âš ï¸  æ¨¡å‹å…¼å®¹æ€§è­¦å‘Š:")
            for warning in compatibility["warnings"]:
                print(f"   - {warning}")
        
        if compatibility["recommendations"]:
            print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for rec in compatibility["recommendations"]:
                print(f"   - {rec}")
        
        # è®¾ç½®adapter
        self.adapter = ModelAdapter(
            model_name=self.model_name,
            model_type=self.model_type,
            api_key=self.api_key or "",  # ç¡®ä¿ä¸æ˜¯None
            api_base=self.api_base or "",  # ç¡®ä¿ä¸æ˜¯None
            **self.optimal_params  # ä½¿ç”¨ä¼˜åŒ–å‚æ•°
        )
        
        # åˆå§‹åŒ–BTPç»„ä»¶
        self.experience_buffer = ExperienceReplayBuffer()
        self.sampler = PrioritizedSampler(sampling_method, sampling_alpha)
        self.p2calculator = P2ValueCalculator(p2value_alpha)
        
        # å¾®è°ƒç®¡ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if model_type == "finetune":
            self.finetuning_manager = MBTPFineTuningManager(
                self.adapter, 
                use_lora=True, 
                output_dir=self.output_dir
            )
        else:
            self.finetuning_manager = None
        
        print(f"ğŸš€ åˆå§‹åŒ–å®Œæˆ:")
        print(f"   æ¨¡å‹: {self.model_name}")
        print(f"   å®¶æ—: {self.model_info.family.value}")
        print(f"   ç±»å‹: {self.model_info.type.value}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"   ä¼˜åŒ–å‚æ•°: {self.optimal_params}")
    
    def load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """åŠ è½½MBPPé…ç½®"""
        return MBPP_CONFIG
    
    def load_dataset(self) -> Dict[str, Any]:
        """åŠ è½½MBPPæ•°æ®é›†"""
        return load_mbpp_problems()
    
    def format_prompt(self, problem: Dict[str, Any]) -> str:
        """ä½¿ç”¨æ™ºèƒ½Promptæ¨¡æ¿æ ¼å¼åŒ–é—®é¢˜"""
        
        # ä¸´æ—¶ç¦ç”¨few-shot examplesä»¥ä¿®å¤0%é€šè¿‡ç‡é—®é¢˜
        # TODO: åç»­ä¼˜åŒ–few-shot examplesçš„promptæ¨¡æ¿
        use_examples = False  # åŸæ¥æ˜¯ï¼šself.model_config.use_examples
        examples = None
        
        if use_examples:
            # ä¸ºDeepSeekç­‰æ¨¡å‹å‡†å¤‡few-shot examples
            examples = self._get_few_shot_examples()
        
        # ä½¿ç”¨æ™ºèƒ½promptå¼•æ“ç”Ÿæˆprompt
        prompt = get_model_prompt(
            model_name=self.model_name,
            dataset="mbpp", 
            problem=problem,
            system_prompt=None,  # ä½¿ç”¨é»˜è®¤ç³»ç»Ÿprompt
            use_examples=use_examples,
            examples=examples
        )
        
        # å¦‚æœè¿”å›çš„æ˜¯messagesæ ¼å¼ï¼ˆOpenAI/Claudeï¼‰ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(prompt, list):
            # æå–ç”¨æˆ·æ¶ˆæ¯å†…å®¹
            for msg in prompt:
                if msg["role"] == "user":
                    return msg["content"]
            return str(prompt)
        
        return prompt
    
    def _get_few_shot_examples(self) -> List[Dict[str, Any]]:
        """è·å–few-shotç¤ºä¾‹ï¼ˆç‰¹åˆ«é’ˆå¯¹DeepSeekç­‰æ¨¡å‹ï¼‰"""
        
        # MBPPçš„ç»å…¸ç¤ºä¾‹ï¼Œå·²ç»éªŒè¯è¿‡æ•ˆæœ
        examples = [
            {
                "problem": "Write a function to find the similar elements from the given two tuple lists.",
                "test_cases": [
                    "assert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)",
                    "assert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)",
                    "assert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)"
                ],
                "solution": """def similar_elements(test_tup1, test_tup2):
  res = tuple(set(test_tup1) & set(test_tup2))
  return (res)"""
            },
            {
                "problem": "Write a python function to identify non-prime numbers.",
                "test_cases": [
                    "assert is_not_prime(2) == False",
                    "assert is_not_prime(10) == True", 
                    "assert is_not_prime(35) == True"
                ],
                "solution": """import math
def is_not_prime(n):
    result = False
    for i in range(2,int(math.sqrt(n)) + 1):
        if n % i == 0:
            result = True
    return result"""
            },
            {
                "problem": "Write a function to find the largest integers from a given list of numbers using heap queue algorithm.",
                "test_cases": [
                    "assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65]",
                    "assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75]",
                    "assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]"
                ],
                "solution": """import heapq as hq
def heap_queue_largest(nums,n):
  largest_nums = hq.nlargest(n, nums)
  return largest_nums"""
            }
        ]
        
        # æ ¹æ®æ¨¡å‹é…ç½®é€‰æ‹©ç¤ºä¾‹æ•°é‡
        max_examples = self.model_config.preferred_examples_count
        return examples[:max_examples]
    
    def phase1_beam_search_sampling(self, problems_list: List[tuple], num_beams: int):
        """é˜¶æ®µ1: Beam Searché‡‡æ ·"""
        print("ğŸ” é˜¶æ®µ1: Beam Searché‡‡æ ·")
        
        for task_id, problem in tqdm(problems_list, desc="Beam Searché‡‡æ ·"):
            prompt = self.format_prompt(problem)
            
            try:
                # ç”Ÿæˆå€™é€‰è§£
                candidates = self.adapter.generate(
                    prompt, 
                    num_beams=num_beams,
                    temperature=0.8,
                    max_tokens=512
                )
                
                # æµ‹è¯•æ¯ä¸ªå€™é€‰è§£
                for candidate in candidates:
                    code = candidate['code']
                    if not code.strip():
                        continue
                    
                    try:
                        # è¿è¡Œæµ‹è¯•
                        test_results = run_tests(code, problem['test_list'])
                        passed_tests = sum(1 for r in test_results.values() if r.get('result', False))
                        total_tests = len(test_results)
                        pass_rate = passed_tests / total_tests if total_tests > 0 else 0.0
                        
                        experience = {
                            'problem_id': str(task_id),
                            'problem_text': problem['text'],
                            'code': code,
                            'possibility': candidate['possibility'],
                            'pass_rate': pass_rate,
                            'passed_tests': passed_tests,
                            'total_tests': total_tests,
                            'test_results': test_results,
                            'beam_rank': candidate['beam_rank']
                        }
                        
                        self.experience_buffer.add_experience(experience)
                        
                    except Exception as e:
                        # æµ‹è¯•å¤±è´¥ä¹Ÿè¦è®°å½•
                        experience = {
                            'problem_id': str(task_id),
                            'problem_text': problem['text'],
                            'code': code,
                            'possibility': candidate['possibility'],
                            'pass_rate': 0.0,
                            'passed_tests': 0,
                            'total_tests': len(problem.get('test_list', [])),
                            'error': str(e),
                            'beam_rank': candidate['beam_rank']
                        }
                        self.experience_buffer.add_experience(experience)
                        
            except Exception as e:
                print(f"âš ï¸  é—®é¢˜ {task_id} ç”Ÿæˆå¤±è´¥: {e}")
                continue
    
    def phase2_pper_training(self, n_iterations: int, batch_size: int):
        """é˜¶æ®µ2: ä¼˜å…ˆç»éªŒå›æ”¾è®­ç»ƒ"""
        print(f"ğŸ¯ é˜¶æ®µ2: ä¼˜å…ˆç»éªŒå›æ”¾è®­ç»ƒ ({n_iterations} è½®è¿­ä»£)")
        
        if self.finetuning_manager is None:
            print("âš ï¸  è·³è¿‡å¾®è°ƒé˜¶æ®µï¼ˆå½“å‰æ¨¡å¼ä¸æ”¯æŒå¾®è°ƒï¼‰")
            return
        
        for iteration in range(n_iterations):
            print(f"\nğŸ“ˆ è¿­ä»£ {iteration + 1}/{n_iterations}")
            
            # è·å–æ‰€æœ‰ç»éªŒ
            all_experiences = self.experience_buffer.get_all_experiences()
            if len(all_experiences) == 0:
                print("âš ï¸  æ²¡æœ‰å¯ç”¨ç»éªŒï¼Œè·³è¿‡æ­¤è½®è¿­ä»£")
                continue
            
            # ä¼˜å…ˆé‡‡æ ·
            sampled_experiences = self.sampler.sample(all_experiences, batch_size)
            print(f"ğŸ“Š é‡‡æ ·äº† {len(sampled_experiences)} ä¸ªç»éªŒç”¨äºè®­ç»ƒ")
            
            # æ‰§è¡Œå¾®è°ƒ
            try:
                self.finetuning_manager.finetune_on_experiences(sampled_experiences)
                print(f"âœ… è¿­ä»£ {iteration + 1} å¾®è°ƒå®Œæˆ")
            except Exception as e:
                print(f"âŒ è¿­ä»£ {iteration + 1} å¾®è°ƒå¤±è´¥: {e}")
                continue
    
    def get_experiment_results(self) -> Dict[str, Any]:
        """è·å–å®éªŒç»“æœ"""
        stats = self.experience_buffer.get_stats(include_samples=True, max_samples=20)
        all_experiences = self.experience_buffer.get_all_experiences()
        
        results = {
            'experiment_type': 'MBPP_BTP',
            'model_name': self.model_name,
            'mode': self.model_type,
            'target_model': self.model_name, # å› ä¸ºå¾®è°ƒæ¨¡å¼ä¸‹ç›®æ ‡æ¨¡å‹å°±æ˜¯å½“å‰æ¨¡å‹
            'sampling_method': self.sampling_method,
            'sampling_alpha': self.sampling_alpha,
            'p2value_alpha': self.p2value_alpha,
            'experience_stats': stats,
            'all_experiences': all_experiences,  # ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„ä»£ç å’Œç»“æœ
            'config': self.get_experiment_config()
        }
        
        # æ‰“å°ä¸€äº›ç”Ÿæˆçš„ä»£ç æ ·æœ¬ç”¨äºè°ƒè¯•
        print("\n" + "="*80)
        print("ğŸ” ç”Ÿæˆä»£ç æ ·æœ¬åˆ†æ (ç”¨äºè°ƒè¯•0%é€šè¿‡ç‡é—®é¢˜)")
        print("="*80)
        
        if 'sample_experiences' in stats and stats['sample_experiences']:
            samples = stats['sample_experiences'][:5]  # åªçœ‹å‰5ä¸ª
            for i, exp in enumerate(samples):
                print(f"\nğŸ“ æ ·æœ¬ {i+1}:")
                print(f"   é—®é¢˜ID: {exp.get('problem_id', 'N/A')}")
                print(f"   é€šè¿‡ç‡: {exp.get('pass_rate', 0):.2f}")
                print(f"   ç”Ÿæˆæ¦‚ç‡: {exp.get('possibility', 0):.4f}")
                print(f"   ç”Ÿæˆä»£ç :")
                print("   " + "-"*60)
                code_lines = str(exp.get('code', '')).split('\n')
                for line in code_lines[:10]:  # åªæ˜¾ç¤ºå‰10è¡Œ
                    print(f"   {line}")
                if len(code_lines) > 10:
                    print(f"   ... (è¿˜æœ‰ {len(code_lines)-10} è¡Œ)")
                print("   " + "-"*60)
                
                # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
                if 'test_results' in exp and exp['test_results']:
                    test_results = exp['test_results']
                    passed = sum(1 for r in test_results.values() if r.get('result', False))
                    total = len(test_results)
                    print(f"   æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
                    
                    # æ˜¾ç¤ºå¤±è´¥çš„æµ‹è¯•ï¼ˆå¦‚æœæœ‰ï¼‰
                    failed_tests = [k for k, v in test_results.items() if not v.get('result', False)]
                    if failed_tests:
                        print(f"   å¤±è´¥æµ‹è¯•: {failed_tests[:3]}")  # åªæ˜¾ç¤ºå‰3ä¸ªå¤±è´¥æµ‹è¯•
        
        print("="*80)
        
        return results


def main():
    parser = argparse.ArgumentParser(
        description='MBPPæ•°æ®é›†çš„BTPå®éªŒ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. æœ¬åœ°æ¨¡å‹BTPå®éªŒ:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model deepseek-ai/deepseek-coder-1.3b-instruct \\
     --mode local --max-problems 50

2. æœ¬åœ°æ¨¡å‹å¾®è°ƒï¼ˆä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•ï¼‰:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model deepseek-ai/deepseek-coder-1.3b-instruct \\
     --mode finetune --max-problems 100

3. æœ¬åœ°æ¨¡å‹å¾®è°ƒï¼ˆè‡ªå®šä¹‰è¾“å‡ºç›®å½•ï¼‰:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model deepseek-ai/deepseek-coder-1.3b-instruct \\
     --mode finetune --max-problems 100 \\
     --output-dir ./my_custom_checkpoints

4. OpenAIå®éªŒ:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model gpt-4 --mode openai \\
     --api-key YOUR_KEY --max-problems 30

5. DeepSeek APIå®éªŒ:
   python experiments/mbpp/step2_btp_experiment.py \\
     --model deepseek-chat --mode deepseek \\
     --api-key YOUR_KEY --max-problems 30
        """)
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--model', type=str, required=True,
                       help='æ¨¡å‹åç§°æˆ–è·¯å¾„')
    parser.add_argument('--mode', type=str, default='local',
                       choices=['local', 'finetune', 'openai', 'deepseek'],
                       help='å®éªŒæ¨¡å¼')
    parser.add_argument('--target-model', type=str, default=None,
                       help='ç›®æ ‡å¾®è°ƒæ¨¡å‹ï¼ˆä»…å¾®è°ƒæ¨¡å¼éœ€è¦ï¼‰')
    
    # APIå‚æ•°
    parser.add_argument('--api-key', type=str,
                       help='APIå¯†é’¥')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--max-problems', type=int, default=50,
                       help='æœ€å¤§é—®é¢˜æ•°é‡')
    parser.add_argument('--num-beams', type=int, default=5,
                       help='Beam Searchæ•°é‡')
    parser.add_argument('--n-iterations', type=int, default=2,
                       help='PPERè®­ç»ƒè¿­ä»£æ¬¡æ•°')
    parser.add_argument('--batch-size', type=int, default=50,
                       help='è®­ç»ƒæ‰¹å¤§å°')
    parser.add_argument('--output-dir', type=str, default='./mbpp_btp_checkpoints',
                       help='æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆä»…å¾®è°ƒæ¨¡å¼ï¼‰')
    
    # BTPç®—æ³•å‚æ•°
    parser.add_argument('--sampling-method', type=str, default='power',
                       choices=['power', 'rank'],
                       help='é‡‡æ ·æ–¹æ³•')
    parser.add_argument('--sampling-alpha', type=float, default=1.0,
                       help='é‡‡æ ·Î±å‚æ•°')
    parser.add_argument('--p2value-alpha', type=float, default=0.5,
                       help='P2Valueæƒé‡Î±')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ—¥å¿—')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.DEBUG if args.debug else logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)
    
    # æ‰“å°é…ç½®
    print("ğŸš€ MBPP BTPå®éªŒé…ç½®:")
    print(f"  æ¨¡å‹: {args.model}")
    print(f"  æ¨¡å¼: {args.mode}")
    print(f"  æœ€å¤§é—®é¢˜æ•°: {args.max_problems}")
    print(f"  é‡‡æ ·æ–¹æ³•: {args.sampling_method}")
    print(f"  é‡‡æ ·Alpha: {args.sampling_alpha}")
    print(f"  P2Value Alpha: {args.p2value_alpha}")
    if args.mode == "finetune":
        print(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = MBBPBTPExperiment(
        model_name=args.model,
        model_type=args.mode,  # ä¿®å¤å‚æ•°åï¼šmode -> model_type
        api_key=args.api_key,
        api_base=None,  # API base å‚æ•°åœ¨ ModelAdapter ä¸­å¤„ç†
        sampling_method=args.sampling_method,
        sampling_alpha=args.sampling_alpha,
        p2value_alpha=args.p2value_alpha,
        output_dir=args.output_dir # ä¼ é€’output_dirå‚æ•°
    )
    
    # è¿è¡Œå®éªŒ
    try:
        results = experiment.run_experiment(
            max_problems=args.max_problems,
            num_beams=args.num_beams,
            n_iterations=args.n_iterations,
            batch_size=args.batch_size
        )
        
        # ä¿å­˜ç»“æœ
        result_file = experiment.save_results(results, "btp_experiment")
        
        print("\nâœ… å®éªŒå®Œæˆ!")
        print(f"ğŸ“Š å®éªŒç»Ÿè®¡:")
        for key, value in results['experience_stats'].items():
            print(f"  {key}: {value}")
        
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        return 0
        
    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main()) 