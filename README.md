# EG-CFG: Execution-Guided Line-by-Line Code Generation 

**EG-CFG** is an inference-time algorithm for code generation that injects real-time execution feedback directly into the model's decoding loop. By incorporating dynamic runtime signals during generation, it steers the model toward solutions that are not only syntactically valid, but also functionally correct and executable.

**SOTA performance on top code generation benchmarks**: from foundational tasks (*MBPP*, *HumanEval*) to extended evaluations (*MBPP-ET*, *HumanEval-ET*) and challenging competitive programming problems (*CodeContests*) - all using open-source models only.

[![arXiv](https://img.shields.io/badge/arXiv-2506.10948-b31b1b)](https://arxiv.org/abs/2506.10948)
[![Video](https://img.shields.io/badge/YouTube-Video-red)](https://youtu.be/YgBcDUQg7As?si=SYyKIyPTdKPNDmO4)
[![Papers with Code](https://img.shields.io/badge/Papers%20with%20Code-View-blue)](https://paperswithcode.com/paper/execution-guided-line-by-line-code-generation)

---

## ğŸ“– è®ºæ–‡æ ¸å¿ƒæ€è·¯ä¸åˆ›æ–°

### æ ¸å¿ƒé—®é¢˜
ä¼ ç»Ÿçš„ä»£ç ç”Ÿæˆæ–¹æ³•é€šå¸¸é‡‡ç”¨"ç”Ÿæˆåæµ‹è¯•"çš„æ¨¡å¼ï¼Œå¯¼è‡´ï¼š
- ç”Ÿæˆçš„ä»£ç å¯èƒ½å­˜åœ¨è¯­æ³•é”™è¯¯æˆ–é€»è¾‘ç¼ºé™·
- æ— æ³•åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åˆ©ç”¨æ‰§è¡Œåé¦ˆ
- éœ€è¦å¤§é‡åå¤„ç†æ¥ç­›é€‰æ­£ç¡®çš„è§£å†³æ–¹æ¡ˆ

### åˆ›æ–°è§£å†³æ–¹æ¡ˆ
EG-CFGæå‡ºäº†**æ‰§è¡Œå¼•å¯¼çš„é€è¡Œç”Ÿæˆ**æ–¹æ³•ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **å®æ—¶æ‰§è¡Œåé¦ˆ**ï¼šåœ¨ä»£ç ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæ¯ç”Ÿæˆå‡ è¡Œä»£ç å°±è¿›è¡Œéƒ¨åˆ†æ‰§è¡Œï¼Œè·å–è¿è¡Œæ—¶çŠ¶æ€
2. **åŠ¨æ€å¼•å¯¼æœºåˆ¶**ï¼šåˆ©ç”¨æ‰§è¡Œåé¦ˆè°ƒæ•´åç»­ç”Ÿæˆçš„æ¦‚ç‡åˆ†å¸ƒï¼Œé¿å…é”™è¯¯è·¯å¾„
3. **BTPå¾®è°ƒæ¡†æ¶**ï¼šBeam Search + Testing + Prioritized Experience Replayçš„å®Œæ•´è®­ç»ƒæµç¨‹

### æŠ€æœ¯è·¯çº¿å›¾

```mermaid
graph TD
    A[ä»£ç ç”Ÿæˆä»»åŠ¡] --> B[EG-CFGæ¨ç†å¼•æ“]
    B --> C[é€è¡Œç”Ÿæˆ]
    C --> D[éƒ¨åˆ†æ‰§è¡Œ]
    D --> E[æ‰§è¡Œåé¦ˆ]
    E --> F{æ˜¯å¦é”™è¯¯?}
    F -->|æ˜¯| G[è°ƒæ•´ç”Ÿæˆç­–ç•¥]
    F -->|å¦| H[ç»§ç»­ç”Ÿæˆ]
    G --> C
    H --> I{ç”Ÿæˆå®Œæˆ?}
    I -->|å¦| C
    I -->|æ˜¯| J[å®Œæ•´è§£å†³æ–¹æ¡ˆ]
    
    K[BTPå¾®è°ƒæ¡†æ¶] --> L[Beam Searché‡‡æ ·]
    L --> M[æµ‹è¯•è¯„ä¼°]
    M --> N[P2Valueè®¡ç®—]
    N --> O[ä¼˜å…ˆç»éªŒå›æ”¾]
    O --> P[æ¨¡å‹å¾®è°ƒ]
    P --> Q[æ”¹è¿›çš„æ¨¡å‹]
```

---

## ğŸ¯ å®éªŒè§„åˆ’ä¸ç›®æ ‡

æˆ‘ä»¬çš„å®éªŒä½“ç³»æ—¨åœ¨éªŒè¯EG-CFGæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå±‚é¢ï¼š

### é˜¶æ®µ1ï¼šåŸºç¡€éªŒè¯å®éªŒ
- **ç›®æ ‡**ï¼šè¯æ˜EG-CFGç›¸æ¯”åŸºçº¿æ–¹æ³•çš„æ€§èƒ½æå‡
- **å®éªŒ**ï¼š`step1_baseline_experiment.py`
- **æŒ‡æ ‡**ï¼šPass@kã€æˆåŠŸç‡ã€ä»£ç è´¨é‡

### é˜¶æ®µ2ï¼šBTPå¾®è°ƒå®éªŒ  
- **ç›®æ ‡**ï¼šéªŒè¯Beam Search + Testing + Prioritized Experience Replayçš„æœ‰æ•ˆæ€§
- **å®éªŒ**ï¼š`step2_btp_experiment.py`ã€`step2_btp_finetune_experiment.py`
- **å…³é”®æŠ€æœ¯**ï¼š
  - P2Valueè®¡ç®—ï¼š`P2Value = Î± Ã— possibility + (1-Î±) Ã— pass_rate`
  - ä¼˜å…ˆé‡‡æ ·ï¼šPower Samplingå’ŒRank Samplingä¸¤ç§ç­–ç•¥
  - LoRAé«˜æ•ˆå¾®è°ƒ

### é˜¶æ®µ3ï¼šæ¶ˆèç ”ç©¶
- **ç›®æ ‡**ï¼šåˆ†æä¸åŒç»„ä»¶çš„è´¡çŒ®åº¦
- **å®éªŒ**ï¼š`step3_ablation_study.py`
- **å¯¹æ¯”å†…å®¹**ï¼šä¸åŒé‡‡æ ·ç­–ç•¥ã€P2Valueæƒé‡ã€å›æ”¾ç¼“å†²åŒºå¤§å°

### é˜¶æ®µ4ï¼šè¶…å‚æ•°ä¼˜åŒ–
- **ç›®æ ‡**ï¼šæ‰¾åˆ°æœ€ä¼˜çš„è¶…å‚æ•°é…ç½®
- **å®éªŒ**ï¼š`step4_hyperparameter_study.py`
- **å…³é”®å‚æ•°**ï¼šÎ±ï¼ˆP2Valueæƒé‡ï¼‰ã€é‡‡æ ·æ¸©åº¦ã€beamå¤§å°

### é˜¶æ®µ5ï¼šå¤§å‹æ¨¡å‹éªŒè¯
- **ç›®æ ‡**ï¼šåœ¨æ›´å¤§è§„æ¨¡æ¨¡å‹ä¸ŠéªŒè¯æ–¹æ³•çš„é€šç”¨æ€§
- **å®éªŒ**ï¼š`big_to_small_finetune_experiment.py`
- **ç­–ç•¥**ï¼šå¤§æ¨¡å‹é‡‡æ · â†’ å°æ¨¡å‹å¾®è°ƒ

---

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

```
eg_cfg-master/
â”œâ”€â”€ eg_cfg/                     # æ ¸å¿ƒç®—æ³•å®ç°
â”‚   â”œâ”€â”€ eg_cfg.py              # EG-CFGä¸»ç®—æ³•
â”‚   â”œâ”€â”€ execution_manager.py   # æ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ model_utils.py         # æ¨¡å‹å·¥å…·
â”‚   â””â”€â”€ mbpp_utils.py          # æ•°æ®é›†å·¥å…·
â”œâ”€â”€ experiments/               # å®éªŒå¥—ä»¶
â”‚   â”œâ”€â”€ step1_baseline_experiment.py      # åŸºçº¿å®éªŒ
â”‚   â”œâ”€â”€ step2_btp_experiment.py          # BTPå®éªŒ
â”‚   â”œâ”€â”€ step2_btp_finetune_experiment.py # BTPå¾®è°ƒå®éªŒ
â”‚   â”œâ”€â”€ step3_ablation_study.py          # æ¶ˆèç ”ç©¶
â”‚   â”œâ”€â”€ step4_hyperparameter_study.py    # è¶…å‚æ•°ç ”ç©¶
â”‚   â”œâ”€â”€ big_to_small_finetune_experiment.py # å¤§å°æ¨¡å‹å®éªŒ
â”‚   â”œâ”€â”€ btp_finetune_framework.py        # BTPæ¡†æ¶æ ¸å¿ƒ
â”‚   â”œâ”€â”€ run_all_experiments.py           # ä¸»è¿è¡Œè„šæœ¬
â”‚   â””â”€â”€ run_*.py                         # å„ç§å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ configs/                   # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ session_config.*.json # ä¼šè¯é…ç½®
â”‚   â””â”€â”€ dynamic_signals_params.json # åŠ¨æ€ä¿¡å·å‚æ•°
â”œâ”€â”€ data/                      # æ•°æ®é›†å’Œç»“æœ
â”œâ”€â”€ scripts/                   # æœåŠ¡å™¨è¿è¡Œè„šæœ¬
â””â”€â”€ traces_dumper/            # æ‰§è¡Œè½¨è¿¹å·¥å…·
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®
```bash
git clone --recurse-submodules git@github.com/OUR_REPO/eg_cfg.git
cd eg_cfg
conda env create -f environment.yml -n eg-cfg-env
conda activate eg-cfg-env
python scripts/redirect_env_to_submodules.py $PWD/submodules/
```

### è¿è¡ŒåŸºç¡€å®éªŒ
```bash
# è¿è¡Œå®Œæ•´å®éªŒå¥—ä»¶
python experiments/run_all_experiments.py --model_name "deepseek-ai/deepseek-coder-1.3b-instruct"

# å¿«é€Ÿæµ‹è¯•
python experiments/run_all_experiments.py --model_name "deepseek-ai/deepseek-coder-1.3b-instruct" --mode quick

# å•ä¸ªå®éªŒ
python experiments/run_all_experiments.py --model_name "deepseek-ai/deepseek-coder-1.3b-instruct" --mode single --single_step btp
```

### è¿è¡ŒBTPå¾®è°ƒå®éªŒ
```bash
# åŸºç¡€BTPå¾®è°ƒ
python experiments/run_btp_finetune_experiment.py \
  --source-model deepseek-ai/deepseek-coder-1.3b-instruct \
  --sampling-method power \
  --sampling-alpha 1.0 \
  --max-problems 50

# å¤§å°æ¨¡å‹é…åˆå¾®è°ƒ
python experiments/big_to_small_finetune_experiment.py \
  --source-model deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct \
  --target-model deepseek-ai/deepseek-coder-1.3b-instruct \
  --max-problems 100
```

---

## ğŸ”§ æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶

### EG-CFGæ¨ç†å¼•æ“
- **æ–‡ä»¶**ï¼š`eg_cfg/eg_cfg.py`
- **åŠŸèƒ½**ï¼šé€è¡Œç”Ÿæˆ + å®æ—¶æ‰§è¡Œåé¦ˆ
- **å…³é”®å‚æ•°**ï¼š
  - `temperature`: é‡‡æ ·æ¸©åº¦
  - `num_candidates`: å€™é€‰æ•°é‡
  - `completion_horizon`: å®Œæˆè§†é‡

### BTPå¾®è°ƒæ¡†æ¶
- **æ–‡ä»¶**ï¼š`experiments/btp_finetune_framework.py`
- **æ ¸å¿ƒç±»**ï¼š
  - `P2ValueCalculator`: P2Valueè®¡ç®—
  - `PrioritizedSampler`: ä¼˜å…ˆé‡‡æ ·å™¨
  - `ExperienceBuffer`: ç»éªŒå›æ”¾ç¼“å†²åŒº
- **é‡‡æ ·ç­–ç•¥**ï¼š
  - Power Sampling: `P(i) = pi^Î± / Î£ pk^Î±`
  - Rank Sampling: `pi = 1/rank(i)`

### æ¨¡å‹ç®¡ç†å™¨
- **æ”¯æŒæ¨¡å‹ç±»å‹**ï¼š
  - æœ¬åœ°æ¨¡å‹ï¼šDeepSeekã€SmolLMã€CodeLlama
  - äº‘ç«¯APIï¼šOpenAI GPTã€DeepSeek API
- **å¾®è°ƒæŠ€æœ¯**ï¼šLoRAé«˜æ•ˆå¾®è°ƒ
- **éƒ¨ç½²æ–¹å¼**ï¼šæœ¬åœ°æ¨ç†ã€æ¨ç†ç«¯ç‚¹

---

## ğŸ“Š å®éªŒç»“æœ

### MBPPå’ŒMBPP-ETåŸºå‡†æµ‹è¯•

| Model               | Method            | MBPP (%) | MBPP-ET (%) | RSR (MBPP) | RSR (MBPP-ET) |
| ------------------- | ----------------- | -------- | ----------- | ---------- | ------------- |
| DeepSeek-Coder 1.3B | Baseline LLM      | 49.4     | 42.6        | 0.0        | 0.0           |
| DeepSeek-Coder 1.3B | EG-CFG (Ours)     | 83.2     | 59.8        | 66.79      | 29.96         |
| DeepSeek-V3-0324    | Baseline LLM      | 82.8     | 64.8        | 0.0        | 0.0           |
| DeepSeek-V3-0324    | **EG-CFG (Ours)** | **96.6** | **73.0**    | **80.23**  | **23.30**     |

### HumanEvalå’ŒHumanEval-ETåŸºå‡†æµ‹è¯•

| Model            | Method            | HumanEval (%) | HumanEval-ET (%) | RSR (HE)  | RSR (HE-ET) |
| ---------------- | ----------------- | ------------- | ---------------- | --------- | ----------- |
| DeepSeek-V3-0324 | Baseline LLM      | 82.92         | 79.20            | 0.0       | 0.0         |
| DeepSeek-V3-0324 | **EG-CFG (Ours)** | **96.95**     | **87.19**        | **78.54** | **38.56**   |

---

## ğŸ›ï¸ å‘½ä»¤è¡Œå‚æ•°è¯´æ˜

### é€šç”¨å‚æ•°
- `--model-name`: æ¨¡å‹åç§°æˆ–è·¯å¾„
- `--dataset`: æ•°æ®é›†é€‰æ‹©ï¼ˆmbpp/humanevalï¼‰
- `--output-dir`: ç»“æœè¾“å‡ºç›®å½•
- `--seed`: éšæœºç§å­

### BTPç‰¹å®šå‚æ•°
- `--sampling-method`: é‡‡æ ·æ–¹æ³•ï¼ˆpower/rankï¼‰
- `--sampling-alpha`: é‡‡æ ·Î±å‚æ•°
- `--p2value-alpha`: P2Valueæƒé‡Î±
- `--num-beams`: Beam Searchå¤§å°
- `--batch-size`: è®­ç»ƒæ‰¹å¤§å°

### LoRAå¾®è°ƒå‚æ•°
- `--lora-r`: LoRA rank
- `--lora-alpha`: LoRA alpha
- `--lora-dropout`: LoRA dropoutç‡

---

## ğŸ”¬ ç ”ç©¶æ–¹å‘ä¸æ‰©å±•

### å½“å‰ç ”ç©¶é‡ç‚¹
1. **å¤šè¯­è¨€ä»£ç ç”Ÿæˆ**ï¼šæ‰©å±•åˆ°Javaã€C++ã€JavaScriptç­‰
2. **é•¿åºåˆ—ä»£ç ç”Ÿæˆ**ï¼šå¤„ç†æ›´å¤æ‚çš„ç¼–ç¨‹ä»»åŠ¡
3. **äº¤äº’å¼ä»£ç è°ƒè¯•**ï¼šç»“åˆæ‰§è¡Œåé¦ˆè¿›è¡Œè‡ªåŠ¨è°ƒè¯•

### æœªæ¥æ‰©å±•è®¡åˆ’
1. **å¼ºåŒ–å­¦ä¹ é›†æˆ**ï¼šå°†æ‰§è¡Œåé¦ˆä½œä¸ºå¥–åŠ±ä¿¡å·
2. **å¤šæ¨¡æ€ä»£ç ç”Ÿæˆ**ï¼šç»“åˆè‡ªç„¶è¯­è¨€æè¿°å’Œç¤ºä¾‹ä»£ç 
3. **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼šæ”¯æŒå¤§è§„æ¨¡æ¨¡å‹çš„åˆ†å¸ƒå¼å¾®è°ƒ

---

## ğŸ“š ç›¸å…³èµ„æº

- **è®ºæ–‡**ï¼š[Execution-Guided Line-by-Line Code Generation](https://arxiv.org/abs/2506.10948)
- **è§†é¢‘ä»‹ç»**ï¼š[YouTubeæ¼”ç¤º](https://youtu.be/YgBcDUQg7As?si=SYyKIyPTdKPNDmO4)
- **Papers with Code**ï¼š[é¡¹ç›®é¡µé¢](https://paperswithcode.com/paper/execution-guided-line-by-line-code-generation)

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼š`git checkout -b feature/amazing-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -m 'Add some amazing feature'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/amazing-feature`
5. æäº¤Pull Request

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [LICENSE](LICENSE) è®¸å¯è¯ã€‚

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- åˆ›å»ºIssue
- å‘é€é‚®ä»¶è‡³é¡¹ç›®ç»´æŠ¤è€…

**EG-CFGé¡¹ç›®è‡´åŠ›äºæ¨è¿›ä»£ç ç”Ÿæˆé¢†åŸŸçš„ç ”ç©¶ï¼Œæ¬¢è¿ç ”ç©¶è€…å’Œå¼€å‘è€…å‚ä¸è´¡çŒ®ï¼**
