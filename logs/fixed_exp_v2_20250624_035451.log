2025-06-24 03:54:56,257 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-24 03:54:56,593 - DEBUG - https://huggingface.co:443 "HEAD /deepseek-ai/deepseek-coder-1.3b-instruct/resolve/main/config.json HTTP/1.1" 200 0
2025-06-24 03:54:57,230 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-24 03:54:58,957 - DEBUG - https://huggingface.co:443 "HEAD /deepseek-ai/deepseek-coder-1.3b-instruct/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-06-24 03:54:59,199 - DEBUG - https://huggingface.co:443 "HEAD /deepseek-ai/deepseek-coder-1.3b-instruct/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-24 03:55:00,012 - DEBUG - https://huggingface.co:443 "HEAD /datasets/google-research-datasets/mbpp/resolve/main/README.md HTTP/1.1" 200 0
2025-06-24 03:55:00,251 - DEBUG - https://huggingface.co:443 "HEAD /datasets/google-research-datasets/mbpp/resolve/4bb6404fdc6cacfda99d4ac4205087b89d32030c/mbpp.py HTTP/1.1" 404 0
2025-06-24 03:55:00,253 - DEBUG - Starting new HTTPS connection (1): s3.amazonaws.com:443
2025-06-24 03:55:00,966 - DEBUG - https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/google-research-datasets/mbpp/google-research-datasets/mbpp.py HTTP/1.1" 404 0
2025-06-24 03:55:01,234 - DEBUG - https://huggingface.co:443 "GET /api/datasets/google-research-datasets/mbpp/revision/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 3937
2025-06-24 03:55:01,897 - DEBUG - https://huggingface.co:443 "HEAD /datasets/google-research-datasets/mbpp/resolve/4bb6404fdc6cacfda99d4ac4205087b89d32030c/.huggingface.yaml HTTP/1.1" 404 0
2025-06-24 03:55:01,903 - DEBUG - Starting new HTTPS connection (1): datasets-server.huggingface.co:443
2025-06-24 03:55:02,234 - DEBUG - https://datasets-server.huggingface.co:443 "GET /info?dataset=google-research-datasets/mbpp HTTP/1.1" 200 None
2025-06-24 03:55:02,491 - DEBUG - https://huggingface.co:443 "GET /api/datasets/google-research-datasets/mbpp/revision/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 3937
2025-06-24 03:55:02,735 - DEBUG - https://huggingface.co:443 "GET /api/datasets/google-research-datasets/mbpp/tree/4bb6404fdc6cacfda99d4ac4205087b89d32030c?recursive=False&expand=False HTTP/1.1" 200 389
2025-06-24 03:55:02,981 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:03,223 - DEBUG - https://huggingface.co:443 "GET /api/datasets/google-research-datasets/mbpp/tree/4bb6404fdc6cacfda99d4ac4205087b89d32030c/full?recursive=False&expand=False HTTP/1.1" 200 938
2025-06-24 03:55:03,231 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-24 03:55:03,492 - DEBUG - https://huggingface.co:443 "GET /api/datasets/google-research-datasets/mbpp/revision/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 3937
2025-06-24 03:55:03,734 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:04,034 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:04,369 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:04,638 - DEBUG - https://huggingface.co:443 "HEAD /datasets/google-research-datasets/mbpp/resolve/4bb6404fdc6cacfda99d4ac4205087b89d32030c/dataset_infos.json HTTP/1.1" 404 0
2025-06-24 03:55:04,909 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:05,235 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:05,575 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:05,989 - DEBUG - https://huggingface.co:443 "POST /api/datasets/google-research-datasets/mbpp/paths-info/4bb6404fdc6cacfda99d4ac4205087b89d32030c HTTP/1.1" 200 235
2025-06-24 03:55:05,994 - DEBUG - Attempting to acquire lock 139968928653264 on /home/ryan/.cache/huggingface/datasets/_home_ryan_.cache_huggingface_datasets_google-research-datasets___mbpp_full_0.0.0_4bb6404fdc6cacfda99d4ac4205087b89d32030c.lock
2025-06-24 03:55:05,995 - DEBUG - Lock 139968928653264 acquired on /home/ryan/.cache/huggingface/datasets/_home_ryan_.cache_huggingface_datasets_google-research-datasets___mbpp_full_0.0.0_4bb6404fdc6cacfda99d4ac4205087b89d32030c.lock
2025-06-24 03:55:05,995 - DEBUG - open file: /home/ryan/.cache/huggingface/datasets/google-research-datasets___mbpp/full/0.0.0/4bb6404fdc6cacfda99d4ac4205087b89d32030c/dataset_info.json
2025-06-24 03:55:05,996 - DEBUG - Attempting to release lock 139968928653264 on /home/ryan/.cache/huggingface/datasets/_home_ryan_.cache_huggingface_datasets_google-research-datasets___mbpp_full_0.0.0_4bb6404fdc6cacfda99d4ac4205087b89d32030c.lock
2025-06-24 03:55:05,997 - DEBUG - Lock 139968928653264 released on /home/ryan/.cache/huggingface/datasets/_home_ryan_.cache_huggingface_datasets_google-research-datasets___mbpp_full_0.0.0_4bb6404fdc6cacfda99d4ac4205087b89d32030c.lock
2025-06-24 03:55:06,041 - DEBUG - Attempting to acquire lock 139968928650480 on /home/ryan/.cache/huggingface/datasets/google-research-datasets___mbpp/full/0.0.0/4bb6404fdc6cacfda99d4ac4205087b89d32030c_builder.lock
2025-06-24 03:55:06,042 - DEBUG - Lock 139968928650480 acquired on /home/ryan/.cache/huggingface/datasets/google-research-datasets___mbpp/full/0.0.0/4bb6404fdc6cacfda99d4ac4205087b89d32030c_builder.lock
2025-06-24 03:55:06,042 - DEBUG - open file: /home/ryan/.cache/huggingface/datasets/google-research-datasets___mbpp/full/0.0.0/4bb6404fdc6cacfda99d4ac4205087b89d32030c/dataset_info.json
2025-06-24 03:55:06,043 - DEBUG - Attempting to release lock 139968928650480 on /home/ryan/.cache/huggingface/datasets/google-research-datasets___mbpp/full/0.0.0/4bb6404fdc6cacfda99d4ac4205087b89d32030c_builder.lock
2025-06-24 03:55:06,043 - DEBUG - Lock 139968928650480 released on /home/ryan/.cache/huggingface/datasets/google-research-datasets___mbpp/full/0.0.0/4bb6404fdc6cacfda99d4ac4205087b89d32030c_builder.lock
BTP Fine-tuning Experiment Configuration:
  Source Model: deepseek-ai/deepseek-coder-1.3b-instruct
  Target Model: same as source
  Dataset: mbpp
  Max Problems: 5
  Sampling Method: power
  Sampling Alpha: 1.0
  P2Value Alpha: 0.5
  Use LoRA: True
  LoRA Config: r=64, alpha=128, dropout=0.1
Loading source model: deepseek-ai/deepseek-coder-1.3b-instruct
Loading dataset: mbpp
Loaded 500 problems
============================================================
BTP Fine-tuning Experiment
============================================================
Phase 1: Beam Search Sampling
Beam Search Sampling:   0%|          | 0/5 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Beam Search Sampling:  20%|██        | 1/5 [00:06<00:24,  6.25s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Beam Search Sampling:  40%|████      | 2/5 [00:11<00:17,  5.75s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Beam Search Sampling:  60%|██████    | 3/5 [00:14<00:09,  4.59s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Beam Search Sampling:  80%|████████  | 4/5 [00:20<00:05,  5.10s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Beam Search Sampling: 100%|██████████| 5/5 [00:25<00:00,  4.82s/it]Beam Search Sampling: 100%|██████████| 5/5 [00:25<00:00,  5.01s/it]

Initial experience buffer stats:
  total_experiences: 10
  avg_p2value: 0.4996776398432116
  std_p2value: 0.00011821584272625105
  avg_pass_rate: 0.0
  fully_passed_count: 0
Phase 2: PPER Training (1 iterations)

Iteration 1/1
Sampled 5 experiences for training
Map:   0%|          | 0/5 [00:00<?, ? examples/s]Map: 100%|██████████| 5/5 [00:00<00:00, 603.08 examples/s]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Starting fine-tuning iteration 0...
  0%|          | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 777, in convert_to_tensors
    tensor = as_tensor(value)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 739, in as_tensor
    return torch.tensor(value)
ValueError: too many dimensions 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ryan/eg-cfg-btp/experiments/step2_btp_finetune_experiment.py", line 632, in <module>
    main() 
  File "/home/ryan/eg-cfg-btp/experiments/step2_btp_finetune_experiment.py", line 617, in main
    results = experiment.run_experiment(
  File "/home/ryan/eg-cfg-btp/experiments/step2_btp_finetune_experiment.py", line 476, in run_experiment
    self.phase2_pper_training(n_iterations, batch_size)
  File "/home/ryan/eg-cfg-btp/experiments/step2_btp_finetune_experiment.py", line 376, in phase2_pper_training
    self._finetune_model(train_dataset, training_args, iteration)
  File "/home/ryan/eg-cfg-btp/experiments/step2_btp_finetune_experiment.py", line 445, in _finetune_model
    trainer.train()
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/trainer.py", line 2500, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/trainer.py", line 5180, in get_batch_samples
    batch_samples += [next(epoch_iterator)]
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/accelerate/data_loader.py", line 567, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 789, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/data/data_collator.py", line 45, in __call__
    return self.torch_call(features)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/data/data_collator.py", line 943, in torch_call
    batch = pad_without_fast_tokenizer_warning(
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/data/data_collator.py", line 66, in pad_without_fast_tokenizer_warning
    padded = tokenizer.pad(*pad_args, **pad_kwargs)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 3397, in pad
    return BatchEncoding(batch_outputs, tensor_type=return_tensors)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 241, in __init__
    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)
  File "/home/ryan/miniforge3/envs/eg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 793, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected).
  0%|          | 0/1 [00:00<?, ?it/s]
